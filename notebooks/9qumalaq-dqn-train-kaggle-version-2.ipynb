{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸŒ Prepare imports","metadata":{}},{"cell_type":"markdown","source":"## ðŸ¦› Install need packages","metadata":{}},{"cell_type":"code","source":"! pip install gdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:05:52.565530Z","iopub.execute_input":"2025-01-19T09:05:52.565776Z","iopub.status.idle":"2025-01-19T09:05:56.714216Z","shell.execute_reply.started":"2025-01-19T09:05:52.565750Z","shell.execute_reply":"2025-01-19T09:05:56.713256Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.12.14)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import gdown\n\nurl = \"https://drive.google.com/uc?id=15uPcQurzdz2aO2Bgf3WLEsQ3nAaMaM8T\"\noutput = 'requirements.txt'\ngdown.download(url, output, quiet=False);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:05:56.714983Z","iopub.execute_input":"2025-01-19T09:05:56.715243Z","iopub.status.idle":"2025-01-19T09:06:01.717179Z","shell.execute_reply.started":"2025-01-19T09:05:56.715211Z","shell.execute_reply":"2025-01-19T09:06:01.716514Z"}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?id=15uPcQurzdz2aO2Bgf3WLEsQ3nAaMaM8T\nTo: /kaggle/working/requirements.txt\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.36k/2.36k [00:00<00:00, 6.73MB/s]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"! pip install -r requirements.txt\n! pip install tianshou coloredlogs\n! pip install --upgrade ipython","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:06:01.717937Z","iopub.execute_input":"2025-01-19T09:06:01.718286Z","iopub.status.idle":"2025-01-19T09:06:59.155592Z","shell.execute_reply.started":"2025-01-19T09:06:01.718266Z","shell.execute_reply":"2025-01-19T09:06:59.154788Z"}},"outputs":[{"name":"stdout","text":"Collecting tianshou@ git+https://github.com/thu-ml/tianshou.git@ade85ab32baab721605508dfd9d460015a1832e5 (from -r requirements.txt (line 107))\n  Cloning https://github.com/thu-ml/tianshou.git (to revision ade85ab32baab721605508dfd9d460015a1832e5) to /tmp/pip-install-khjs8b2z/tianshou_db26d01f0cf14a5c90423b974baf9d3e\n  Running command git clone --filter=blob:none --quiet https://github.com/thu-ml/tianshou.git /tmp/pip-install-khjs8b2z/tianshou_db26d01f0cf14a5c90423b974baf9d3e\n  Running command git rev-parse -q --verify 'sha^ade85ab32baab721605508dfd9d460015a1832e5'\n  Running command git fetch -q https://github.com/thu-ml/tianshou.git ade85ab32baab721605508dfd9d460015a1832e5\n  Running command git checkout -q ade85ab32baab721605508dfd9d460015a1832e5\n  Resolved https://github.com/thu-ml/tianshou.git to commit ade85ab32baab721605508dfd9d460015a1832e5\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nCollecting absl-py==2.1.0 (from -r requirements.txt (line 1))\n  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting asttokens==2.4.1 (from -r requirements.txt (line 2))\n  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\nCollecting attrs==23.2.0 (from -r requirements.txt (line 3))\n  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\nCollecting blinker==1.8.1 (from -r requirements.txt (line 4))\n  Downloading blinker-1.8.1-py3-none-any.whl.metadata (1.6 kB)\nCollecting certifi==2024.2.2 (from -r requirements.txt (line 5))\n  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\nCollecting charset-normalizer==3.3.2 (from -r requirements.txt (line 6))\n  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\nRequirement already satisfied: click==8.1.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (8.1.7)\nCollecting cloudpickle==3.0.0 (from -r requirements.txt (line 8))\n  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\nCollecting coloredlogs==15.0.1 (from -r requirements.txt (line 9))\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: comm==0.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.2.2)\nCollecting contourpy==1.2.1 (from -r requirements.txt (line 11))\n  Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\nRequirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.12.1)\nCollecting dash==2.17.0 (from -r requirements.txt (line 13))\n  Downloading dash-2.17.0-py3-none-any.whl.metadata (10 kB)\nCollecting dash-bootstrap-components==1.6.0 (from -r requirements.txt (line 14))\n  Downloading dash_bootstrap_components-1.6.0-py3-none-any.whl.metadata (5.2 kB)\nCollecting dash-core-components==2.0.0 (from -r requirements.txt (line 15))\n  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting dash-html-components==2.0.0 (from -r requirements.txt (line 16))\n  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting dash-table==5.0.0 (from -r requirements.txt (line 17))\n  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting dash_ag_grid==31.2.0 (from -r requirements.txt (line 18))\n  Downloading dash_ag_grid-31.2.0-py3-none-any.whl.metadata (5.2 kB)\nCollecting debugpy==1.8.1 (from -r requirements.txt (line 19))\n  Downloading debugpy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nCollecting decorator==5.1.1 (from -r requirements.txt (line 20))\n  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\nCollecting deepdiff==7.0.1 (from -r requirements.txt (line 21))\n  Downloading deepdiff-7.0.1-py3-none-any.whl.metadata (6.8 kB)\nCollecting distlib==0.3.8 (from -r requirements.txt (line 22))\n  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\nCollecting executing==2.0.1 (from -r requirements.txt (line 23))\n  Downloading executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: Farama-Notifications==0.0.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (0.0.4)\nCollecting fastjsonschema==2.20.0 (from -r requirements.txt (line 25))\n  Downloading fastjsonschema-2.20.0-py3-none-any.whl.metadata (2.1 kB)\nCollecting filelock==3.13.4 (from -r requirements.txt (line 26))\n  Downloading filelock-3.13.4-py3-none-any.whl.metadata (2.8 kB)\nCollecting flake8==7.0.0 (from -r requirements.txt (line 27))\n  Downloading flake8-7.0.0-py2.py3-none-any.whl.metadata (3.8 kB)\nCollecting Flask==3.0.3 (from -r requirements.txt (line 28))\n  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\nCollecting fonttools==4.51.0 (from -r requirements.txt (line 29))\n  Downloading fonttools-4.51.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m159.5/159.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting fsspec==2024.3.1 (from -r requirements.txt (line 30))\n  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\nCollecting grpcio==1.62.2 (from -r requirements.txt (line 31))\n  Downloading grpcio-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting gymnasium==0.28.1 (from -r requirements.txt (line 32))\n  Downloading gymnasium-0.28.1-py3-none-any.whl.metadata (9.2 kB)\nCollecting h5py==3.11.0 (from -r requirements.txt (line 33))\n  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nCollecting humanfriendly==10.0 (from -r requirements.txt (line 34))\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nCollecting idna==3.7 (from -r requirements.txt (line 35))\n  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\nCollecting importlib_metadata==7.1.0 (from -r requirements.txt (line 36))\n  Downloading importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\nCollecting ipykernel==6.29.4 (from -r requirements.txt (line 37))\n  Downloading ipykernel-6.29.4-py3-none-any.whl.metadata (6.3 kB)\nCollecting ipython==8.23.0 (from -r requirements.txt (line 38))\n  Downloading ipython-8.23.0-py3-none-any.whl.metadata (4.9 kB)\nCollecting ipywidgets==8.1.2 (from -r requirements.txt (line 39))\n  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: itsdangerous==2.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 40)) (2.2.0)\nCollecting jax-jumpy==1.0.0 (from -r requirements.txt (line 41))\n  Downloading jax_jumpy-1.0.0-py3-none-any.whl.metadata (15 kB)\nCollecting jedi==0.19.1 (from -r requirements.txt (line 42))\n  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\nCollecting Jinja2==3.1.3 (from -r requirements.txt (line 43))\n  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\nCollecting jsonschema==4.22.0 (from -r requirements.txt (line 44))\n  Downloading jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\nCollecting jsonschema-specifications==2023.12.1 (from -r requirements.txt (line 45))\n  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\nCollecting jupyter_client==8.6.1 (from -r requirements.txt (line 46))\n  Downloading jupyter_client-8.6.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: jupyter_core==5.7.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 47)) (5.7.2)\nCollecting jupyterlab_widgets==3.0.10 (from -r requirements.txt (line 48))\n  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\nCollecting kiwisolver==1.4.5 (from -r requirements.txt (line 49))\n  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\nCollecting llvmlite==0.40.1 (from -r requirements.txt (line 50))\n  Downloading llvmlite-0.40.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\nCollecting Markdown==3.6 (from -r requirements.txt (line 51))\n  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\nCollecting MarkupSafe==2.1.5 (from -r requirements.txt (line 52))\n  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nCollecting matplotlib==3.8.4 (from -r requirements.txt (line 53))\n  Downloading matplotlib-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\nRequirement already satisfied: matplotlib-inline==0.1.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 54)) (0.1.7)\nCollecting mccabe==0.7.0 (from -r requirements.txt (line 55))\n  Downloading mccabe-0.7.0-py2.py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 56)) (1.3.0)\nRequirement already satisfied: nbformat==5.10.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 57)) (5.10.4)\nRequirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 58)) (1.6.0)\nCollecting networkx==3.3 (from -r requirements.txt (line 59))\n  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\nCollecting numba==0.57.1 (from -r requirements.txt (line 60))\n  Downloading numba-0.57.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\nCollecting numpy==1.24.4 (from -r requirements.txt (line 61))\n  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from -r requirements.txt (line 62))\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from -r requirements.txt (line 63))\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from -r requirements.txt (line 64))\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from -r requirements.txt (line 65))\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from -r requirements.txt (line 66))\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from -r requirements.txt (line 67))\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from -r requirements.txt (line 68))\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from -r requirements.txt (line 69))\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from -r requirements.txt (line 70))\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from -r requirements.txt (line 71))\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from -r requirements.txt (line 72))\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from -r requirements.txt (line 73))\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting ordered-set==4.1.0 (from -r requirements.txt (line 74))\n  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: overrides==7.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 75)) (7.7.0)\nCollecting packaging==24.0 (from -r requirements.txt (line 76))\n  Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 77)) (2.2.2)\nRequirement already satisfied: parso==0.8.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 78)) (0.8.4)\nCollecting pettingzoo==1.24.3 (from -r requirements.txt (line 79))\n  Downloading pettingzoo-1.24.3-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: pexpect==4.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 80)) (4.9.0)\nCollecting pillow==10.3.0 (from -r requirements.txt (line 81))\n  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\nCollecting platformdirs==4.2.1 (from -r requirements.txt (line 82))\n  Downloading platformdirs-4.2.1-py3-none-any.whl.metadata (11 kB)\nCollecting plotly==5.22.0 (from -r requirements.txt (line 83))\n  Downloading plotly-5.22.0-py3-none-any.whl.metadata (7.1 kB)\nCollecting prompt-toolkit==3.0.43 (from -r requirements.txt (line 84))\n  Downloading prompt_toolkit-3.0.43-py3-none-any.whl.metadata (6.5 kB)\nCollecting protobuf==5.26.1 (from -r requirements.txt (line 85))\n  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nCollecting psutil==5.9.8 (from -r requirements.txt (line 86))\n  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nRequirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 87)) (0.7.0)\nCollecting pure-eval==0.2.2 (from -r requirements.txt (line 88))\n  Downloading pure_eval-0.2.2-py3-none-any.whl.metadata (6.2 kB)\nCollecting pycodestyle==2.11.1 (from -r requirements.txt (line 89))\n  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl.metadata (4.5 kB)\nCollecting pyflakes==3.2.0 (from -r requirements.txt (line 90))\n  Downloading pyflakes-3.2.0-py2.py3-none-any.whl.metadata (3.5 kB)\nCollecting Pygments==2.17.2 (from -r requirements.txt (line 91))\n  Downloading pygments-2.17.2-py3-none-any.whl.metadata (2.6 kB)\nCollecting pyparsing==3.1.2 (from -r requirements.txt (line 92))\n  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\nCollecting python-dateutil==2.9.0.post0 (from -r requirements.txt (line 93))\n  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\nCollecting pytz==2024.1 (from -r requirements.txt (line 94))\n  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\nCollecting pyzmq==26.0.2 (from -r requirements.txt (line 95))\n  Downloading pyzmq-26.0.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: referencing==0.35.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 96)) (0.35.1)\nCollecting requests==2.31.0 (from -r requirements.txt (line 97))\n  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\nCollecting retrying==1.3.4 (from -r requirements.txt (line 98))\n  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\nCollecting rpds-py==0.18.1 (from -r requirements.txt (line 99))\n  Downloading rpds_py-0.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nCollecting scipy==1.13.0 (from -r requirements.txt (line 100))\n  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting six==1.16.0 (from -r requirements.txt (line 101))\n  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\nCollecting stack-data==0.6.3 (from -r requirements.txt (line 102))\n  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\nCollecting sympy==1.12 (from -r requirements.txt (line 103))\n  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\nCollecting tenacity==8.2.3 (from -r requirements.txt (line 104))\n  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\nCollecting tensorboard==2.16.2 (from -r requirements.txt (line 105))\n  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: tensorboard-data-server==0.7.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 106)) (0.7.2)\nCollecting torch==2.3.0 (from -r requirements.txt (line 108))\n  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nCollecting tornado==6.4 (from -r requirements.txt (line 109))\n  Downloading tornado-6.4-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nCollecting tqdm==4.66.2 (from -r requirements.txt (line 110))\n  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting traitlets==5.14.3 (from -r requirements.txt (line 111))\n  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\nCollecting triton==2.3.0 (from -r requirements.txt (line 112))\n  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting typing_extensions==4.11.0 (from -r requirements.txt (line 113))\n  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting tzdata==2024.1 (from -r requirements.txt (line 114))\n  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\nCollecting urllib3==2.2.1 (from -r requirements.txt (line 115))\n  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\nCollecting virtualenv==20.26.0 (from -r requirements.txt (line 116))\n  Downloading virtualenv-20.26.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: wcwidth==0.2.13 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 117)) (0.2.13)\nCollecting Werkzeug==3.0.2 (from -r requirements.txt (line 118))\n  Downloading werkzeug-3.0.2-py3-none-any.whl.metadata (4.1 kB)\nCollecting widgetsnbextension==4.0.10 (from -r requirements.txt (line 119))\n  Downloading widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\nCollecting zipp==3.18.1 (from -r requirements.txt (line 120))\n  Downloading zipp-3.18.1-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash==2.17.0->-r requirements.txt (line 13)) (75.1.0)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython==8.23.0->-r requirements.txt (line 38)) (1.2.2)\nINFO: pip is looking at multiple versions of tianshou to determine which version is compatible with other requirements. This could take a while.\nCollecting referencing==0.35.1 (from -r requirements.txt (line 96))\n  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\nCollecting pandas==2.2.2 (from -r requirements.txt (line 77))\n  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\nCollecting nbformat==5.10.4 (from -r requirements.txt (line 57))\n  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\nINFO: pip is still looking at multiple versions of tianshou to determine which version is compatible with other requirements. This could take a while.\nCollecting matplotlib-inline==0.1.7 (from -r requirements.txt (line 54))\n  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\nCollecting jupyter_core==5.7.2 (from -r requirements.txt (line 47))\n  Downloading jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)\nCollecting comm==0.2.2 (from -r requirements.txt (line 10))\n  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n\u001b[31mERROR: Package 'tianshou' requires a different Python: 3.10.12 not in '<4.0,>=3.11'\u001b[0m\u001b[31m\n\u001b[0mCollecting tianshou\n  Downloading tianshou-0.5.1-py3-none-any.whl.metadata (34 kB)\nCollecting coloredlogs\n  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: gymnasium>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (0.29.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tianshou) (4.67.1)\nRequirement already satisfied: numpy>1.16.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (1.26.4)\nRequirement already satisfied: tensorboard>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (2.17.1)\nRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (2.5.1+cu121)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (0.60.0)\nRequirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (3.12.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tianshou) (24.2)\nRequirement already satisfied: pettingzoo>=1.22 in /usr/local/lib/python3.10/dist-packages (from tianshou) (1.24.0)\nCollecting humanfriendly>=9.1 (from coloredlogs)\n  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26.0->tianshou) (3.1.0)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26.0->tianshou) (4.12.2)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26.0->tianshou) (0.0.4)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->tianshou) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>1.16.0->tianshou) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>1.16.0->tianshou) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>1.16.0->tianshou) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>1.16.0->tianshou) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>1.16.0->tianshou) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>1.16.0->tianshou) (2.4.1)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (1.68.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (3.7)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (75.1.0)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (1.17.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (3.1.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (3.16.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.4.0->tianshou) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.5.0->tianshou) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>1.16.0->tianshou) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>1.16.0->tianshou) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>1.16.0->tianshou) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>1.16.0->tianshou) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>1.16.0->tianshou) (2024.2.0)\nDownloading tianshou-0.5.1-py3-none-any.whl (163 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m163.1/163.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, tianshou\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 tianshou-0.5.1\nRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (7.34.0)\nCollecting ipython\n  Downloading ipython-8.31.0-py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython) (4.4.2)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython) (1.2.2)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython) (0.19.2)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.9.0)\nRequirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/dist-packages (from ipython) (3.0.48)\nRequirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (2.18.0)\nCollecting stack_data (from ipython)\n  Using cached stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\nCollecting traitlets>=5.13.0 (from ipython)\n  Using cached traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: typing_extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.12.2)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\nCollecting executing>=1.2.0 (from stack_data->ipython)\n  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\nRequirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython) (3.0.0)\nCollecting pure-eval (from stack_data->ipython)\n  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nDownloading ipython-8.31.0-py3-none-any.whl (821 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m821.6/821.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\nDownloading executing-2.1.0-py2.py3-none-any.whl (25 kB)\nDownloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\nInstalling collected packages: pure-eval, traitlets, executing, stack_data, ipython\n  Attempting uninstall: traitlets\n    Found existing installation: traitlets 5.7.1\n    Uninstalling traitlets-5.7.1:\n      Successfully uninstalled traitlets-5.7.1\n  Attempting uninstall: ipython\n    Found existing installation: ipython 7.34.0\n    Uninstalling ipython-7.34.0:\n      Successfully uninstalled ipython-7.34.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.31.0 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed executing-2.1.0 ipython-8.31.0 pure-eval-0.2.3 stack_data-0.6.3 traitlets-5.14.3\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ! pip install -U ipywidgets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:06:59.156478Z","iopub.execute_input":"2025-01-19T09:06:59.156701Z","iopub.status.idle":"2025-01-19T09:06:59.160511Z","shell.execute_reply.started":"2025-01-19T09:06:59.156682Z","shell.execute_reply":"2025-01-19T09:06:59.159634Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## ðŸ¦ Imports","metadata":{}},{"cell_type":"code","source":"import gymnasium\nimport numpy as np\nfrom gymnasium.spaces import Discrete, MultiDiscrete\nfrom gymnasium import spaces\nimport random\n\nfrom IPython.display import clear_output\nimport time\nfrom pettingzoo import AECEnv\nfrom pettingzoo.utils import agent_selector, wrappers\nimport matplotlib.pyplot as plt\nfrom tianshou.env.pettingzoo_env import PettingZooEnv\n\nfrom typing import Optional, Tuple\nfrom tianshou.policy import BasePolicy, DQNPolicy, RainbowPolicy, MultiAgentPolicyManager, RandomPolicy\nfrom tianshou.trainer import OffpolicyTrainer\nfrom tianshou.utils.net.common import Net\nfrom tianshou.env import DummyVectorEnv\nfrom copy import deepcopy\nfrom tianshou.data import Collector, VectorReplayBuffer\n\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tianshou.utils import TensorboardLogger\n\nimport torch\n\nimport random\nimport os\n\nNUM_ITERS = 400\nPLAYS = {\"bastaushy\": 0, \"qostaushy\": 0}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:06:59.161189Z","iopub.execute_input":"2025-01-19T09:06:59.161400Z","iopub.status.idle":"2025-01-19T09:07:18.751366Z","shell.execute_reply.started":"2025-01-19T09:06:59.161383Z","shell.execute_reply":"2025-01-19T09:07:18.750602Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/util.py:55: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs; see https://jax.readthedocs.io/en/latest/aot.html. For example, replace xla_computation(f)(*xs) with jit(f).lower(*xs).compiler_ir('hlo'). See CHANGELOG.md for 0.4.30 for more examples.\n  from jax import xla_computation as _xla_computation\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# ðŸ˜ AEC environment https://pettingzoo.farama.org/api/aec/#about-aec","metadata":{}},{"cell_type":"markdown","source":"## ðŸ¦‰ Create environment","metadata":{}},{"cell_type":"code","source":"class TogyzQumalaqEnv(AECEnv):\n    \"\"\"\n    The \"name\" metadata allows the environment to be pretty printed.\n    \"\"\"\n\n    metadata = {\n        \"render_modes\": [\"ansi\", \"human\"],\n        \"name\": \"togyzqumalaq_v0\"\n        }\n\n    def __init__(self, render_mode=None):\n        \"\"\"\n        The init method takes in environment arguments and\n         should define the following attributes:\n        - otaular\n        - tuzdyq\n        - qazandar\n        - possible_agents\n        - render_mode\n        \"\"\"\n        self.otaular = []\n        self.tuzdyq = []\n        self.qazandar = []\n        self.direction = []\n        self.agents = [\"bastaushy\", \"qostaushy\"]\n        self.possible_agents = self.agents[:]\n        self.action_spaces = {i: spaces.Discrete(9) for i in self.agents}\n        self.observation_spaces = {\n            i: spaces.Dict(\n                {\n                    \"observation\":\n                        MultiDiscrete([100] * 18 + [10] * 2 + [162] * 2 + [2]),\n                    \"action_mask\":\n                        Discrete(9),\n                }\n            )\n            for i in self.agents\n        }\n        self.render_mode = render_mode\n\n    # Action space should be defined here.\n    def action_space(self, agent):\n        return self.action_spaces[agent]\n\n    # Observation space should be defined here.\n    def observation_space(self, agent):\n        return self.observation_spaces[agent]\n\n    def render(self):\n        \"\"\"\n        Renders the environment. In human mode,\n        it can print to terminal, open\n        up a graphical window, or open up some\n        other display that\n        a human can see and understand.\n        \"\"\"\n        \"\"\"Renders the environment.\"\"\"\n        if self.render_mode is None:\n            gymnasium.logger.warn(\n                \"You are calling render method without \"\n                \"specifying any render mode.\"\n            )\n            return\n\n        if len(self.agents) == 2:\n            points_bastaushy_x = np.array([i * 2 for i in range(10)])\n            points_bastaushy_y = np.array([i % 5 for i in range(50)])\n\n            qazandar = self.qazandar\n            otaular = self.otaular\n            tuzdyq = self.tuzdyq\n            x = np.arange(-3, 225, 1)\n            y = -1\n\n            text_kwargs = dict(ha='center', va='center', fontsize=12)\n            plt.figure(figsize=(15, 4))\n\n            for i in range(9):\n                # qostaushy's part\n                plt.scatter(np.repeat(\n                    points_bastaushy_x + 25 * i, 5)[:otaular[17 - i]],\n                            points_bastaushy_y[:otaular[17 - i]], marker='o')\n                # vertical lines\n                plt.plot(np.repeat(25 * i - 2, len(x)),\n                         np.arange(-7, 5, 12 / len(x)))\n                # bastaushy's part\n                plt.scatter(np.repeat(points_bastaushy_x + 25 * i, 5)[:otaular[i]],\n                                points_bastaushy_y[:otaular[i]] - 6, marker='o')\n            \n            # horizontal line\n            x_lims = np.arange(-3, 245, 1)\n            plt.plot(x_lims, np.repeat(y, len(x_lims)))\n            # last vertical line\n            plt.plot(np.repeat(25 * 9 - 2, 13),\n                     np.arange(-7, 6, 1))\n        \n            for i in range(9):\n                # bastaushy's qumalaqtar\n                plt.text(25 * i + 10, -7,\n                         f'{i} ({otaular[i]})', **text_kwargs)\n                # qostaushy's qumalaqtar\n                plt.text(25 * i + 10, 5,\n                         f'{17 - i} ({otaular[17 - i]})', **text_kwargs)\n            # bastaushy qazan's qumalaqtar\n            plt.text(235, -4,\n                     f'qazan: {qazandar[0]}', **text_kwargs)\n            # qostaushy qazan's qumalaqtar\n            plt.text(235, 2,\n                     f'qazan: {qazandar[1]}', **text_kwargs)\n            # bastaushy tuzdyq's qumalaqtar\n            plt.text(235, -6,\n                     f'tuzdyq: {tuzdyq[0]}', **text_kwargs)\n            # qostaushy tuzdyq's qumalaqtar\n            plt.text(235, 0,\n                     f'tuzdyq: {tuzdyq[1]}', **text_kwargs)\n            plt.xticks([])\n            plt.yticks([])\n            plt.show()\n        else:\n            if self.render_mode == \"human\":\n                print(\"Game over\")\n        time.sleep(1)\n        #clear_output()\n\n    def _legal_moves(self, agent):\n        cur_player = self.possible_agents.index(agent)\n        opp_player = (cur_player + 1) % 2\n        return [item for item in range(9) if self.tuzdyq[opp_player] != item  + cur_player * 9 and self.otaular[item + cur_player * 9] > 0]\n\n    def observe(self, agent):\n        \"\"\"\n        Observe should return the observation of the specified agent. This function\n        should return a sane observation (though not necessarily the most up to date possible)\n        at any time after reset() is called.\n        \"\"\"\n        # observation of one agent is the previous state of the other\n        legal_moves = self._legal_moves(agent) if agent == self.agent_selection else []\n        action_mask = np.zeros(9, \"int8\")\n        \n        for i in legal_moves:\n            action_mask[i] = 1\n        observation = tuple(\n            self.otaular + self.tuzdyq + self.qazandar + [self.possible_agents.index(self.agent_selection)]\n        )\n        return {\"observation\": observation, \"action_mask\": action_mask}\n\n    def close(self):\n        \"\"\"\n        Close should release any graphical displays, subprocesses, network connections\n        or any other environment data which should not be kept around after the\n        user is no longer using the environment.\n        \"\"\"\n        pass\n\n    def reset(self, seed=None, options=None):\n        \"\"\"\n        Reset needs to initialize the following attributes\n        - agents\n        - rewards\n        - _cumulative_rewards\n        - terminations\n        - truncations\n        - infos\n        - agent_selection\n        \"\"\"\n        self.agents = self.possible_agents[:]\n        self.rewards = {agent: 0 for agent in self.agents}\n        self._cumulative_rewards = {agent: 0 for agent in self.agents}\n        self.otaular = [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n        self.direction = [list(range(18)), [9, 10, 11, 12, 13, 14, 15, 16, 17, 0, 1, 2, 3, 4, 5, 6, 7, 8]]\n        self.tuzdyq = [-1, -1]\n        self.qazandar = [0, 0]\n        self.terminations = {agent: False for agent in self.agents}\n        self.truncations = {agent: False for agent in self.agents}\n        self.infos = {agent: {} for agent in self.agents}\n        self.num_moves = 0\n        observation = tuple(\n            self.otaular + self.tuzdyq + self.qazandar + [0]\n        )\n        self.observations = {agent: observation for agent in self.agents}\n        \"\"\"\n        Our agent_selector utility allows easy cyclic stepping through the agents list.\n        \"\"\"\n        self._agent_selector = agent_selector(self.agents)\n        self.agent_selection = self._agent_selector.next()\n\n    def step(self, action):\n        \"\"\"\n        step(action) takes in an action for the current agent (specified by\n        agent_selection) and needs to update\n        - rewards\n        - _cumulative_rewards (accumulating the rewards)\n        - terminations\n        - truncations\n        - infos\n        - agent_selection (to the next agent)\n        And any internal state used by observe() or render()\n        \"\"\"\n        if (\n            self.terminations[self.agent_selection]\n            or self.truncations[self.agent_selection]\n        ):\n            # handles stepping an agent which is already dead\n            # accepts a None action for the one agent, and moves the agent_selection to\n            # the next dead agent,  or if there are no more dead agents, to the next live agent\n            self._was_dead_step(action)\n            return\n        self.rewards = {agent: 0 for agent in self.agents}\n        cur_player = self.possible_agents.index(self.agent_selection)\n        opp_player = (cur_player + 1) % 2\n        self.num_moves += 1\n        if self.render_mode == \"human\":\n            print(f'MOVE #{self.num_moves}')\n        # The truncations dictionary must be updated for all players.\n        self.truncations = {\n            agent: self.num_moves >= NUM_ITERS for agent in self.agents\n        }\n        # distribute qumalaqs\n        if cur_player == 1:\n            action += 9\n        if self.render_mode == \"human\":\n            print(f'{self.agent_selection} made action {action}')\n        num_qumalaq = self.otaular[action]\n        idx_action = self.direction[cur_player].index(action)\n        if self.otaular[action] == 1:\n            self.otaular[self.direction[cur_player][idx_action + 1]] += 1\n            self.otaular[action] -= 1\n        else:\n            i = 1\n            coef = 1\n            if self.otaular[action] / 18 > 1:\n                coef = int(self.otaular[action] / 18) + 1\n            while self.otaular[action] > coef:\n                self.otaular[self.direction[cur_player][(idx_action + i) % 18]] += 1\n                self.otaular[action] -= 1\n                i += 1\n        # check tuzdyq & add rewards to qazandar\n        reward = 0\n        if self.tuzdyq[cur_player] < 0 and self.check_tuzdyq(self.agent_selection, action, num_qumalaq):\n            reward += 3\n            if self.render_mode == \"human\":\n                print(f'{self.agent_selection} won tuzdyq {reward}')\n                \n            #******* awarding a rewards for receiving tuzdyq **********\n            # self.rewards[self.agent_selection] += 50\n            # self.rewards[self.possible_agents[opp_player]] -= 50\n        else:\n\n            if num_qumalaq > 1:\n                last_otau = self.direction[cur_player][(idx_action + num_qumalaq - 1) % 18]\n            else:\n                last_otau = self.direction[cur_player][(idx_action + num_qumalaq) % 18]\n\n            if (last_otau in range(opp_player * 9, (opp_player + 1) * 9) and\n                    self.otaular[last_otau] % 2 == 0):\n                reward += self.otaular[last_otau]\n                if self.render_mode == \"human\":\n                    print(f'{self.agent_selection} won {reward}')\n                self.otaular[last_otau] = 0\n            if (self.tuzdyq[cur_player] >= 0 and\n                    self.otaular[self.tuzdyq[cur_player]] > 0):\n                reward += self.otaular[self.tuzdyq[cur_player]]\n                if self.render_mode == \"human\":\n                    print(f'{self.agent_selection} won tuzdyq {self.otaular[self.tuzdyq[cur_player]]}')\n                self.otaular[self.tuzdyq[cur_player]] = 0\n        if self.render_mode == \"human\":\n            print(f'{self.agent_selection} won total {reward}')\n        self.qazandar[cur_player] += reward\n\n        #******* awarding a rewards from otaular **********\n        self.rewards[self.agent_selection] += reward\n        self.rewards[self.possible_agents[opp_player]] -= reward\n        \n        # check if there is a winner\n        winner = self.check_for_winner()\n        if winner:\n            self.terminations = {i: True for i in self.agents}\n            if self.render_mode == \"human\":\n                print(f'{self.agent_selection} won the game!!!')\n                \n            #******* awarding a reward for winning a game **********\n            self.rewards[self.agent_selection] += self.qazandar[opp_player]\n            self.rewards[self.possible_agents[opp_player]] -= self.qazandar[opp_player]\n            for i in range(9):\n                self.rewards[self.agent_selection] += self.otaular[i + 9 * opp_player]\n                self.rewards[self.possible_agents[opp_player]] -= self.otaular[i + 9 * opp_player]\n            \n        # selects the next agent.\n        self.agent_selection = self._agent_selector.next()\n        # Adds .rewards to ._cumulative_rewards\n        self._accumulate_rewards()\n\n        total_rewards = sum(self.rewards.values())\n        assert total_rewards == 0, f\"Error: Total reward is not zero: {total_rewards}\"\n        total_qumalaqs = 0\n        for i in self.otaular:\n            total_qumalaqs += i\n        for i in self.qazandar:\n            total_qumalaqs += i\n        assert total_qumalaqs == 162, f\"Error: Total qumalaqs is not equal to 162: {total_qumalaqs}\"\n        if self.render_mode == \"human\":\n            self.render()\n\n    def check_tuzdyq(self, agent, action, num_qumalaq):\n        cur_player = self.possible_agents.index(agent)\n        opp_player = (cur_player + 1) % 2\n        idx = self.direction[cur_player].index(action)\n\n        if num_qumalaq > 1:\n            last_otau = self.direction[cur_player][(idx + num_qumalaq - 1) % 18]\n        else:\n            last_otau = self.direction[cur_player][(idx + num_qumalaq) % 18]\n\n        if (last_otau in range(opp_player * 9, (opp_player + 1) * 9) and\n                self.otaular[last_otau] == 3 and last_otau != 17 - cur_player * 9 and\n                abs(last_otau - self.tuzdyq[opp_player]) != 9):\n            self.tuzdyq[cur_player] = last_otau\n            self.otaular[last_otau] = 0\n            if self.render_mode == \"human\":\n                print(f'{agent} got tuzdyq {last_otau}!')\n            return True\n\n        return False\n\n    def check_atsyrau(self, agent):\n        cur_player = self.possible_agents.index(agent)\n        opp_player = (cur_player + 1) % 2\n\n        for idx, i in enumerate(\n                self.otaular[cur_player * 9: (cur_player + 1) * 9]):\n            if i > 0 and idx + cur_player * 9 != self.tuzdyq[opp_player]:\n                return False\n        if self.render_mode == \"human\":\n            print(f'{agent} reached atsyrau')\n        return True\n\n    def check_for_winner(self):\n        cur_player = self.possible_agents.index(self.agent_selection)\n        opp_player = (cur_player + 1) % 2\n        if self.qazandar[cur_player] > 81:\n            PLAYS[self.agent_selection] += 1\n            return True\n        if (self.check_atsyrau(self.possible_agents[opp_player])\n                and self.qazandar[opp_player] <= 81):\n            PLAYS[self.agent_selection] += 1\n            return True\n        return False\n\n\ndef _get_env(render_mode=None):\n    \"\"\"This function is needed to provide callables for DummyVectorEnv.\"\"\"\n    def env(render_mode=None):\n        \"\"\"\n        The env function often wraps the environment in wrappers by default.\n        You can find full documentation for these methods\n        elsewhere in the developer documentation.\n        \"\"\"\n        internal_render_mode = render_mode \\\n            if render_mode != \"ansi\" else \"human\"\n        env = TogyzQumalaqEnv(render_mode=internal_render_mode)\n        # This wrapper is only for environments\n        # which print results to the terminal\n        if render_mode == \"ansi\":\n            env = wrappers.CaptureStdoutWrapper(env)\n        # this wrapper helps error handling for discrete action spaces\n        env = wrappers.AssertOutOfBoundsWrapper(env)\n        # Provides a wide vareity of helpful user errors\n        # Strongly recommended\n        env = wrappers.OrderEnforcingWrapper(env)\n        return env\n    return PettingZooEnv(env(render_mode=render_mode))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:07:18.753793Z","iopub.execute_input":"2025-01-19T09:07:18.754031Z","iopub.status.idle":"2025-01-19T09:07:18.795109Z","shell.execute_reply.started":"2025-01-19T09:07:18.754010Z","shell.execute_reply":"2025-01-19T09:07:18.793912Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# ðŸ¦ Prepare data","metadata":{}},{"cell_type":"markdown","source":"## ðŸ† Create folders","metadata":{}},{"cell_type":"markdown","source":"### ðŸ¦‚ Log folders","metadata":{}},{"cell_type":"code","source":"!mkdir logs\nLOGS_PATH = os.path.join('/', 'kaggle', 'working', 'logs')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:07:18.797939Z","iopub.execute_input":"2025-01-19T09:07:18.798260Z","iopub.status.idle":"2025-01-19T09:07:18.971270Z","shell.execute_reply.started":"2025-01-19T09:07:18.798230Z","shell.execute_reply":"2025-01-19T09:07:18.970350Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### ðŸ¦† Model folders","metadata":{}},{"cell_type":"code","source":"!mkdir models\nMODELS_PATH = os.path.join('/', 'kaggle', 'working', 'models')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:07:18.972284Z","iopub.execute_input":"2025-01-19T09:07:18.972523Z","iopub.status.idle":"2025-01-19T09:07:19.106734Z","shell.execute_reply.started":"2025-01-19T09:07:18.972493Z","shell.execute_reply":"2025-01-19T09:07:19.105890Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## ðŸ  Training parameters","metadata":{}},{"cell_type":"code","source":"NET_ARCHS = [[64,128,128,64], [1024, 2048, 2048, 1024], [2048, 4096, 4096, 2048], [2048, 4096, 8192, 4096, 2048]]\n\nMAX_EPOCHS = 4000\n\nSTEP_PER_EPOCH = 10000\n\nSTEP_PER_COLLECT = 1000\n\nEPISODE_PER_TEST = 200\n\nUPDATE_PER_STEP = 1 / STEP_PER_COLLECT\n\nBATCH_SIZE = 1024\n\nLR = 1e-04\n\nDF = 0.99\n\nTRAIN_EPS = 0.15\n\nTEST_EPS = 0.05\n\nTRAIN_NUM = 100\n\nTEST_NUM = 10\n\nagent_idx2name = {0: 'bastaushy', 1: 'qostaushy'}\n\nSEED = 888","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:07:19.107629Z","iopub.execute_input":"2025-01-19T09:07:19.107892Z","iopub.status.idle":"2025-01-19T09:07:19.113009Z","shell.execute_reply.started":"2025-01-19T09:07:19.107870Z","shell.execute_reply":"2025-01-19T09:07:19.112123Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# ðŸ¼ DQN agent to play vs a random policy agent https://pettingzoo.farama.org/tutorials/tianshou/intermediate/","metadata":{}},{"cell_type":"markdown","source":"## ðŸœ Set net architectures","metadata":{}},{"cell_type":"code","source":"def arch2str(net_arch):\n    out = str(net_arch[0])\n    for i in net_arch[1:]:\n        out += 'x' + str(i)\n    return out\n\ndef str2arch(inp):\n    lst = inp.split('x')\n    return [int(i) for i in lst]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:07:19.113889Z","iopub.execute_input":"2025-01-19T09:07:19.114166Z","iopub.status.idle":"2025-01-19T09:07:19.126491Z","shell.execute_reply.started":"2025-01-19T09:07:19.114137Z","shell.execute_reply":"2025-01-19T09:07:19.125792Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## ðŸ« Prepare main functionsÂ¶","metadata":{}},{"cell_type":"code","source":"def _get_agents_dqn(\n    agent_train: Optional[BasePolicy] = None,\n    agent_opponent: Optional[BasePolicy] = None,\n    optim: Optional[torch.optim.Optimizer] = None,\n    agent_type = None,\n    net_arch = [64, 128, 128, 64]\n) -> Tuple[BasePolicy, torch.optim.Optimizer, list]:\n    env = _get_env()\n    observation_space = (\n        env.observation_space[\"observation\"]\n        if isinstance(env.observation_space, gymnasium.spaces.Dict)\n        else env.observation_space\n    )\n    if agent_train is None:\n        # model\n        net = Net(\n            state_shape=observation_space.shape or observation_space.n,\n            action_shape=env.action_space.shape or env.action_space.n,\n            hidden_sizes=net_arch,\n            device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n        )\n\n        if optim is None:\n            optim = torch.optim.Adam(net.parameters(), lr=LR)\n        agent_train = DQNPolicy(\n            model=net,\n            optim=optim,\n            discount_factor=DF,\n            estimation_step=3,\n            target_update_freq=320,\n            action_space=env.action_space,\n            observation_space=observation_space\n        ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n    if agent_opponent is None:\n        agent_opponent = RandomPolicy(action_space=env.action_space)\n        \n    if agent_type==\"qostaushy\":\n        agents = [agent_opponent, agent_train]\n    else:\n        agents = [agent_train, agent_opponent]\n    policy = MultiAgentPolicyManager(policies=agents, env=env)\n    return policy, optim, env.agents","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:07:19.127307Z","iopub.execute_input":"2025-01-19T09:07:19.127496Z","iopub.status.idle":"2025-01-19T09:07:19.139557Z","shell.execute_reply.started":"2025-01-19T09:07:19.127479Z","shell.execute_reply":"2025-01-19T09:07:19.138927Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def play_vs_random(agent, type, seed=777):\n    \n    env = _get_env()\n\n    rand_policy = RandomPolicy(action_space=env.action_space)\n    env.action_space.seed(seed)\n\n    if type == 'qostaushy':\n        policies = MultiAgentPolicyManager(policies=[rand_policy, agent], env=env)\n    else:\n        policies = MultiAgentPolicyManager(policies=[agent, rand_policy], env=env)\n\n    env = DummyVectorEnv([lambda: env])\n\n    collector = Collector(policies, env)\n\n    result = collector.collect(n_episode=100)#, reset_before_collect=True)\n    \n    print(f'Agent {type} vs random', PLAYS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:07:19.140269Z","iopub.execute_input":"2025-01-19T09:07:19.140458Z","iopub.status.idle":"2025-01-19T09:07:19.155254Z","shell.execute_reply.started":"2025-01-19T09:07:19.140441Z","shell.execute_reply":"2025-01-19T09:07:19.154600Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def play_vs_others(agent, type, opponents):\n\n    for n_agent_opp, agent_opponent in enumerate(opponents):\n        \n        env = _get_env()#render_mode='human')\n\n        if type == \"bastaushy\":\n\n            policies = MultiAgentPolicyManager(policies=[agent, agent_opponent], env=env)\n            \n        else:\n            \n            policies = MultiAgentPolicyManager(policies=[agent_opponent, agent], env=env)\n        \n        test_envs = DummyVectorEnv([lambda: env for _ in range(10)])\n\n        collector = Collector(policies, test_envs, exploration_noise=False)\n\n        result = collector.collect(n_episode=1)\n        \n    print(f'{type} plays vs others: {PLAYS}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:07:19.155985Z","iopub.execute_input":"2025-01-19T09:07:19.156195Z","iopub.status.idle":"2025-01-19T09:07:19.170230Z","shell.execute_reply.started":"2025-01-19T09:07:19.156177Z","shell.execute_reply":"2025-01-19T09:07:19.169394Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## ðŸ§ Training agents","metadata":{}},{"cell_type":"markdown","source":"### ðŸ¦š Method train agent","metadata":{}},{"cell_type":"code","source":"def train_agent_dqn(index, net_arch, agent_idx, agent_train=None, agent_opponent=None, seed=777):\n    # Before evaluate this cell run the cell with env\n    # ======== Step 1: Environment setup =========\n    train_envs = DummyVectorEnv([_get_env for _ in range(TRAIN_NUM)])\n    test_envs = DummyVectorEnv([_get_env for _ in range(TEST_NUM)])\n    \n    # seed\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    train_envs.seed(seed)\n    test_envs.seed(seed)\n    \n    # ======== Step 2: Agent setup =========\n    policy, optim, agents = _get_agents_dqn(agent_train=agent_train, agent_opponent=agent_opponent, agent_type=agent_idx2name[agent_idx], net_arch=net_arch)\n    \n    # # ======== Step 3: Collector setup =========\n    train_collector = Collector(\n        policy,\n        train_envs,\n        VectorReplayBuffer(100_000, len(train_envs)),\n        exploration_noise=True,\n    )\n    test_collector = Collector(policy, test_envs, exploration_noise=True)\n\n    train_collector.collect(n_step=BATCH_SIZE * TRAIN_NUM)  # batch size * training_num\n    log_path = os.path.join(LOGS_PATH, str(index))\n    writer = SummaryWriter(log_path)\n    logger = TensorboardLogger(writer)\n    \n    # ======== Step 4: Callback functions setup =========\n    def save_best_fn(policy):\n        model_save_path = os.path.join(MODELS_PATH, f'policy_dqn_{arch2str(net_arch)}_{index}.pth')\n        os.makedirs(MODELS_PATH, exist_ok=True)\n        \n        torch.save(policy.policies[agents[agent_idx]].state_dict(), model_save_path)\n        global PLAYS\n        PLAYS [\"bastaushy\"], PLAYS[\"qostaushy\"] = 0, 0\n        net = Net(\n            state_shape=(23,),\n            action_shape=env.action_space.shape or env.action_space.n,\n            hidden_sizes=net_arch,\n            device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n        )\n        \n        agent_trained = DQNPolicy(\n            model=net,\n            optim = torch.optim.Adam(net.parameters(), lr=LR),\n            discount_factor=DF,\n            estimation_step=3,\n            target_update_freq=320,\n            action_space=env.action_space,\n            observation_space=env.observation_space\n        ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        agent_trained.load_state_dict(torch.load(f\"{MODELS_PATH}/policy_dqn_{arch2str(net_arch)}_{index}.pth\", map_location=torch.device('cpu')))\n        play_vs_random(agent_trained, agent_idx2name[agent_idx], seed=seed)\n        # PLAYS [\"bastaushy\"], PLAYS[\"qostaushy\"] = 0, 0\n        # play_vs_others(agent_trained, agent_idx2name[agent_idx], agents_trained[(agent_idx + 1) % 2 : len(agents_trained) : 2])\n    \n    def stop_fn(mean_rewards):\n        return mean_rewards >= 160\n    \n    def train_fn(epoch, env_step):\n        policy.policies[agents[agent_idx]].set_eps(get_train_eps(epoch))\n    \n    def test_fn(epoch, env_step):\n        policy.policies[agents[agent_idx]].set_eps(TEST_EPS)\n    \n    def reward_metric(rews):\n        return rews[:, agent_idx]\n    \n    def get_train_eps(epoch):\n        return max(0.01, 1.0 - epoch / MAX_EPOCHS)\n\n    def get_test_eps(epoch):\n        return 0.05  # ÐŸÐ¾ÑÑ‚Ð¾ÑÐ½Ð½Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ\n\n    # ======== Step 5: Run the trainer =========\n    result = OffpolicyTrainer(\n        policy=policy,\n        train_collector=train_collector,\n        test_collector=test_collector,\n        max_epoch=MAX_EPOCHS,\n        step_per_epoch=STEP_PER_EPOCH,\n        step_per_collect=STEP_PER_COLLECT,\n        episode_per_test=EPISODE_PER_TEST,\n        batch_size=BATCH_SIZE,\n        train_fn=train_fn,\n        test_fn=test_fn,\n        stop_fn=stop_fn,\n        save_best_fn=save_best_fn,\n        update_per_step=UPDATE_PER_STEP,\n        test_in_train=False,\n        reward_metric=reward_metric,\n        verbose=True,\n        show_progress=True,\n        logger=logger\n    ).run()\n    \n    # return result, policy.policies[agents[1]]\n    print(f\"\\n==========Result==========\\n{result}\")\n    print(f\"\\n(the trained policy can be accessed via policy.policies[agents[{agent_idx}]])\")\n    return policy.policies[agents[agent_idx]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:07:19.171091Z","iopub.execute_input":"2025-01-19T09:07:19.171357Z","iopub.status.idle":"2025-01-19T09:07:19.182950Z","shell.execute_reply.started":"2025-01-19T09:07:19.171330Z","shell.execute_reply":"2025-01-19T09:07:19.182207Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# ðŸ‘ Self-play training","metadata":{}},{"cell_type":"markdown","source":"### ðŸ¸ Download previous models","metadata":{}},{"cell_type":"code","source":"# urls = [\"https://drive.google.com/uc?id=1gU6xKG0OsC9PnJ7v2nCqAh9p-U6rco4u\",\n#         \"https://drive.google.com/uc?id=1El8_10upA_es-tyqQfGxzdHfvBEqIkc0\",  \n#         \"https://drive.google.com/uc?id=1rGM4TK_QnjWdToy7fkUPmdgL0ybh4w3L\",\n#         \"https://drive.google.com/uc?id=14bwcfNbiOVlNCpIguqpfCcHeeXtpZvsJ\", \n#        ]\n\n# for idx, url in enumerate(urls):\n#     output = f'models/policy_dqn_2048x4096x4096x2048_{idx}.pth'\n#     gdown.download(url, output, quiet=False);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:07:19.183826Z","iopub.execute_input":"2025-01-19T09:07:19.184048Z","iopub.status.idle":"2025-01-19T09:07:19.198021Z","shell.execute_reply.started":"2025-01-19T09:07:19.184030Z","shell.execute_reply":"2025-01-19T09:07:19.197320Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### ðŸŠ Load trained models","metadata":{}},{"cell_type":"code","source":"# import copy\n\n# env = _get_env()\n\n# agents_trained = []\n\n# net_arch = [2048, 4096, 4096, 2048]\n# for idx in range(len(urls)):\n\n#     agent_idx = idx % 2\n#     net = Net(\n#             state_shape=(23,),\n#             action_shape=env.action_space.shape or env.action_space.n,\n#             hidden_sizes=net_arch,\n#             device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n#             )\n            \n#     agent_trained1 = DQNPolicy(\n#             model=net,\n#             optim = torch.optim.Adam(net.parameters(), lr=LR),\n#             discount_factor=DF,\n#             estimation_step=3,\n#             target_update_freq=320,\n#             action_space=env.action_space,\n#             observation_space=env.observation_space\n#     ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n#     arch_name = arch2str(net_arch)\n#     agent_trained1.load_state_dict(torch.load(f\"{MODELS_PATH}/policy_dqn_{arch_name}_{idx}.pth\", map_location=torch.device('cpu')))\n#     agent_trained = copy.deepcopy(agent_trained1)\n#     agents_trained.append(agent_trained)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:07:19.198669Z","iopub.execute_input":"2025-01-19T09:07:19.198891Z","iopub.status.idle":"2025-01-19T09:07:19.210186Z","shell.execute_reply.started":"2025-01-19T09:07:19.198873Z","shell.execute_reply":"2025-01-19T09:07:19.209594Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"### ðŸª² Play trained models","metadata":{}},{"cell_type":"code","source":"# for i in range(len(agents_trained)):\n    \n#     agent_idx = i % 2\n    \n#     PLAYS = {\"bastaushy\": 0, \"qostaushy\": 0}\n    \n#     play_vs_others(agents_trained[i], agent_idx2name[agent_idx], agents_trained[(agent_idx + 1) % 2 : len(agents_trained) : 2])\n#     print('----------------------------------------------')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:07:19.210934Z","iopub.execute_input":"2025-01-19T09:07:19.211162Z","iopub.status.idle":"2025-01-19T09:07:19.226591Z","shell.execute_reply.started":"2025-01-19T09:07:19.211144Z","shell.execute_reply":"2025-01-19T09:07:19.225934Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"### ðŸª² Play trained models vs random","metadata":{}},{"cell_type":"code","source":"# for i in range(len(agents_trained)):\n#     agent_idx = i % 2\n#     # play trained agents with random policy\n#     PLAYS = {\"bastaushy\": 0, \"qostaushy\": 0}\n#     play_vs_random(agents_trained[i], agent_idx2name[agent_idx], seed=891)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:07:19.227324Z","iopub.execute_input":"2025-01-19T09:07:19.227581Z","iopub.status.idle":"2025-01-19T09:07:19.240611Z","shell.execute_reply.started":"2025-01-19T09:07:19.227545Z","shell.execute_reply":"2025-01-19T09:07:19.239888Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## ðŸ£ Main loop","metadata":{}},{"cell_type":"markdown","source":"### ðŸŸ Set parameters ","metadata":{}},{"cell_type":"code","source":"net_arch = NET_ARCHS[3]\n\narch_name = arch2str(net_arch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:07:19.243236Z","iopub.execute_input":"2025-01-19T09:07:19.243457Z","iopub.status.idle":"2025-01-19T09:07:19.254023Z","shell.execute_reply.started":"2025-01-19T09:07:19.243429Z","shell.execute_reply":"2025-01-19T09:07:19.253305Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"### ðŸ¨ Self-play","metadata":{}},{"cell_type":"code","source":"for i in range(2):\n        agent_idx = i % 2\n        ### training\n        env = _get_env()\n    \n        net = Net(\n            state_shape=(23,),\n            action_shape=env.action_space.shape or env.action_space.n,\n            hidden_sizes=net_arch,\n            device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n        )\n        \n        agent_trained = DQNPolicy(\n            model=net,\n            optim = torch.optim.Adam(net.parameters(), lr=LR),\n            discount_factor=DF,\n            estimation_step=3,\n            target_update_freq=320,\n            action_space=env.action_space,\n            observation_space=env.observation_space\n        ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n        if i > 1: \n            net_opp = Net(\n                state_shape=(23,),\n                action_shape=env.action_space.shape or env.action_space.n,\n                hidden_sizes=net_arch,\n                device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n            )\n        \n            agent_trained_opp = DQNPolicy(\n                model=net_opp,\n                optim = torch.optim.Adam(net.parameters(), lr=LR),\n                discount_factor=DF,\n                estimation_step=3,\n                target_update_freq=320,\n                action_space=env.action_space,\n                observation_space=env.observation_space\n            ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n            net_prev = Net(\n                state_shape=(23,),\n                action_shape=env.action_space.shape or env.action_space.n,\n                hidden_sizes=net_arch,\n                device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n            )\n        \n            agent_trained_prev = DQNPolicy(\n                model=net_prev,\n                optim = torch.optim.Adam(net.parameters(), lr=LR),\n                discount_factor=DF,\n                estimation_step=3,\n                target_update_freq=320,\n                action_space=env.action_space,\n                observation_space=env.observation_space\n            ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n            \n            ###load policy models\n\n            idx_opp = random.choice([i for i in range((i + 1) % 2, len(agents_trained), 2)])\n            agent_trained_opp.load_state_dict(torch.load(f\"{MODELS_PATH}/policy_dqn_{arch_name}_{idx_opp}.pth\", map_location=torch.device('cpu')))\n            agent_trained_prev.load_state_dict(torch.load(f\"{MODELS_PATH}/policy_dqn_{arch_name}_{i-2}.pth\", map_location=torch.device('cpu')))\n\n            print(f'{agent_idx2name[agent_idx]} is training vs {agent_idx2name[(agent_idx + 1) % 2]} {idx_opp}')\n            #train_agent_dqn(index=i, net_arch=net_arch, agent_idx=agent_idx, agent_train=agent_trained_prev, agent_opponent=agent_trained_opp)\n            train_agent_dqn(index=i, net_arch=net_arch, agent_idx=agent_idx, agent_opponent=agent_trained_opp, seed=SEED)\n        else:\n            train_agent_dqn(index=i, net_arch=net_arch, agent_idx=agent_idx)\n\n        # agent_trained.load_state_dict(torch.load(f\"{MODELS_PATH}/policy_dqn_{arch_name}_{i}.pth\", map_location=torch.device('cpu')))\n        # agent_trained1 = copy.deepcopy(agent_trained)\n        # agents_trained.append(agent_trained1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:07:55.047295Z","iopub.execute_input":"2025-01-19T09:07:55.047598Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-14-1aaf7da17f55>:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  agent_trained.load_state_dict(torch.load(f\"{MODELS_PATH}/policy_dqn_{arch2str(net_arch)}_{index}.pth\", map_location=torch.device('cpu')))\n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 11, 'qostaushy': 89}\n","output_type":"stream"},{"name":"stderr","text":"Epoch #1: 10001it [00:03, 2813.73it/s, bastaushy/loss=112.376, env_step=10000, len=135, n/ep=17, n/st=1000, rew=-6.47]                           \n<ipython-input-14-1aaf7da17f55>:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  agent_trained.load_state_dict(torch.load(f\"{MODELS_PATH}/policy_dqn_{arch2str(net_arch)}_{index}.pth\", map_location=torch.device('cpu')))\n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 26, 'qostaushy': 74}\nEpoch #1: test_reward: -61.985000 Â± 74.022056, best_reward: -61.985000 Â± 74.022056 in #1\n","output_type":"stream"},{"name":"stderr","text":"Epoch #2: 10001it [00:02, 4525.38it/s, bastaushy/loss=120.483, env_step=20000, len=106, n/ep=10, n/st=1000, rew=19.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #2: test_reward: -77.695000 Â± 61.040249, best_reward: -61.985000 Â± 74.022056 in #1\n","output_type":"stream"},{"name":"stderr","text":"Epoch #3: 10001it [00:02, 4457.85it/s, bastaushy/loss=118.002, env_step=30000, len=113, n/ep=8, n/st=1000, rew=44.50]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #3: test_reward: -73.480000 Â± 71.138735, best_reward: -61.985000 Â± 74.022056 in #1\n","output_type":"stream"},{"name":"stderr","text":"Epoch #4: 10001it [00:02, 4406.91it/s, bastaushy/loss=117.743, env_step=40000, len=118, n/ep=8, n/st=1000, rew=-0.12]                           \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 17, 'qostaushy': 83}\nEpoch #4: test_reward: -41.975000 Â± 85.702243, best_reward: -41.975000 Â± 85.702243 in #4\n","output_type":"stream"},{"name":"stderr","text":"Epoch #5: 10001it [00:02, 4416.40it/s, bastaushy/loss=115.810, env_step=50000, len=143, n/ep=6, n/st=1000, rew=-3.67]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #5: test_reward: -71.885000 Â± 73.300967, best_reward: -41.975000 Â± 85.702243 in #4\n","output_type":"stream"},{"name":"stderr","text":"Epoch #6: 10001it [00:02, 4411.46it/s, bastaushy/loss=115.632, env_step=60000, len=96, n/ep=6, n/st=1000, rew=-1.00]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #6: test_reward: -71.980000 Â± 70.445721, best_reward: -41.975000 Â± 85.702243 in #4\n","output_type":"stream"},{"name":"stderr","text":"Epoch #7: 10001it [00:02, 4481.52it/s, bastaushy/loss=116.998, env_step=70000, len=127, n/ep=12, n/st=1000, rew=-26.92]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #7: test_reward: -51.665000 Â± 79.837665, best_reward: -41.975000 Â± 85.702243 in #4\n","output_type":"stream"},{"name":"stderr","text":"Epoch #8: 10001it [00:02, 4422.27it/s, bastaushy/loss=116.561, env_step=80000, len=123, n/ep=7, n/st=1000, rew=12.57]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #8: test_reward: -56.625000 Â± 77.573219, best_reward: -41.975000 Â± 85.702243 in #4\n","output_type":"stream"},{"name":"stderr","text":"Epoch #9: 10001it [00:02, 4483.43it/s, bastaushy/loss=116.718, env_step=90000, len=162, n/ep=4, n/st=1000, rew=84.50]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #9: test_reward: -81.625000 Â± 59.120338, best_reward: -41.975000 Â± 85.702243 in #4\n","output_type":"stream"},{"name":"stderr","text":"Epoch #10: 10001it [00:02, 4355.38it/s, bastaushy/loss=117.511, env_step=100000, len=99, n/ep=8, n/st=1000, rew=1.62]                             \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 41, 'qostaushy': 59}\nEpoch #10: test_reward: -40.175000 Â± 82.674448, best_reward: -40.175000 Â± 82.674448 in #10\n","output_type":"stream"},{"name":"stderr","text":"Epoch #11: 10001it [00:02, 4427.47it/s, bastaushy/loss=118.565, env_step=110000, len=119, n/ep=10, n/st=1000, rew=35.50]                           \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 48, 'qostaushy': 52}\nEpoch #11: test_reward: -1.450000 Â± 86.758213, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #12: 10001it [00:02, 4608.00it/s, bastaushy/loss=119.749, env_step=120000, len=123, n/ep=4, n/st=1000, rew=1.00]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #12: test_reward: -48.990000 Â± 79.531880, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #13: 10001it [00:02, 4571.52it/s, bastaushy/loss=120.632, env_step=130000, len=127, n/ep=10, n/st=1000, rew=-2.20]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #13: test_reward: -32.935000 Â± 84.388629, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #14: 10001it [00:02, 4449.42it/s, bastaushy/loss=123.024, env_step=140000, len=156, n/ep=2, n/st=1000, rew=2.00]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #14: test_reward: -50.190000 Â± 79.096295, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #15: 10001it [00:02, 4404.14it/s, bastaushy/loss=125.265, env_step=150000, len=127, n/ep=11, n/st=1000, rew=6.09]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #15: test_reward: -97.750000 Â± 43.052729, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #16: 10001it [00:02, 4518.03it/s, bastaushy/loss=126.121, env_step=160000, len=140, n/ep=5, n/st=1000, rew=-15.60]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #16: test_reward: -67.635000 Â± 66.485425, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #17: 10001it [00:02, 4597.73it/s, bastaushy/loss=125.496, env_step=170000, len=127, n/ep=9, n/st=1000, rew=-4.33]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #17: test_reward: -65.405000 Â± 70.275252, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #18: 10001it [00:02, 4634.70it/s, bastaushy/loss=126.364, env_step=180000, len=101, n/ep=9, n/st=1000, rew=-20.44]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #18: test_reward: -55.900000 Â± 81.239153, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #19: 10001it [00:02, 4455.56it/s, bastaushy/loss=125.718, env_step=190000, len=92, n/ep=6, n/st=1000, rew=93.33]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #19: test_reward: -71.105000 Â± 69.850655, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #20: 10001it [00:02, 4424.75it/s, bastaushy/loss=126.848, env_step=200000, len=103, n/ep=7, n/st=1000, rew=38.86]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #20: test_reward: -73.815000 Â± 67.331128, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #21: 10001it [00:02, 4469.12it/s, bastaushy/loss=126.887, env_step=210000, len=139, n/ep=7, n/st=1000, rew=-13.14]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #21: test_reward: -54.390000 Â± 79.592009, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #22: 10001it [00:02, 4488.43it/s, bastaushy/loss=124.502, env_step=220000, len=108, n/ep=5, n/st=1000, rew=58.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #22: test_reward: -42.135000 Â± 84.616705, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #23: 10001it [00:02, 4466.04it/s, bastaushy/loss=125.061, env_step=230000, len=159, n/ep=10, n/st=1000, rew=5.50]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #23: test_reward: -56.155000 Â± 77.700392, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #24: 10001it [00:02, 4422.29it/s, bastaushy/loss=124.475, env_step=240000, len=105, n/ep=9, n/st=1000, rew=-11.67]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #24: test_reward: -53.735000 Â± 77.458600, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #25: 10001it [00:02, 4464.30it/s, bastaushy/loss=125.316, env_step=250000, len=110, n/ep=7, n/st=1000, rew=65.57]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #25: test_reward: -72.080000 Â± 65.867015, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #26: 10001it [00:02, 4458.98it/s, bastaushy/loss=125.203, env_step=260000, len=125, n/ep=8, n/st=1000, rew=1.25]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #26: test_reward: -73.650000 Â± 61.849313, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #27: 10001it [00:02, 4454.49it/s, bastaushy/loss=125.727, env_step=270000, len=140, n/ep=4, n/st=1000, rew=38.75]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #27: test_reward: -72.065000 Â± 66.410095, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #28: 10001it [00:02, 4495.00it/s, bastaushy/loss=126.303, env_step=280000, len=113, n/ep=8, n/st=1000, rew=40.62]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #28: test_reward: -49.810000 Â± 80.393370, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #29: 10001it [00:02, 4413.17it/s, bastaushy/loss=128.129, env_step=290000, len=99, n/ep=10, n/st=1000, rew=37.80]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #29: test_reward: -52.140000 Â± 78.135270, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #30: 10001it [00:02, 4424.34it/s, bastaushy/loss=126.362, env_step=300000, len=111, n/ep=6, n/st=1000, rew=35.67]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #30: test_reward: -52.565000 Â± 78.221134, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #31: 10001it [00:02, 4464.92it/s, bastaushy/loss=124.852, env_step=310000, len=103, n/ep=7, n/st=1000, rew=-14.71]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #31: test_reward: -51.155000 Â± 78.460888, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #32: 10001it [00:02, 4423.39it/s, bastaushy/loss=124.444, env_step=320000, len=125, n/ep=14, n/st=1000, rew=-12.36]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #32: test_reward: -50.150000 Â± 78.914115, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #33: 10001it [00:02, 4487.03it/s, bastaushy/loss=127.362, env_step=330000, len=149, n/ep=7, n/st=1000, rew=65.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #33: test_reward: -84.495000 Â± 50.314312, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #34: 10001it [00:02, 4490.33it/s, bastaushy/loss=126.637, env_step=340000, len=142, n/ep=11, n/st=1000, rew=61.36]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #34: test_reward: -66.790000 Â± 69.809855, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #35: 10001it [00:02, 4482.72it/s, bastaushy/loss=124.831, env_step=350000, len=128, n/ep=10, n/st=1000, rew=-29.90]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #35: test_reward: -56.890000 Â± 76.332810, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #36: 10001it [00:02, 4533.63it/s, bastaushy/loss=122.546, env_step=360000, len=129, n/ep=4, n/st=1000, rew=57.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #36: test_reward: -66.175000 Â± 69.184784, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #37: 10001it [00:02, 4527.96it/s, bastaushy/loss=118.917, env_step=370000, len=88, n/ep=9, n/st=1000, rew=12.56]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #37: test_reward: -31.880000 Â± 85.757773, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #38: 10001it [00:02, 4364.07it/s, bastaushy/loss=117.005, env_step=380000, len=125, n/ep=2, n/st=1000, rew=94.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #38: test_reward: -77.095000 Â± 59.637371, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #39: 10001it [00:02, 4437.10it/s, bastaushy/loss=113.125, env_step=390000, len=118, n/ep=10, n/st=1000, rew=-1.80]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #39: test_reward: -58.110000 Â± 76.999272, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #40: 10001it [00:02, 4476.29it/s, bastaushy/loss=110.700, env_step=400000, len=130, n/ep=8, n/st=1000, rew=-2.38]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #40: test_reward: -67.280000 Â± 69.933051, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #41: 10001it [00:02, 4579.01it/s, bastaushy/loss=110.735, env_step=410000, len=135, n/ep=7, n/st=1000, rew=-7.14]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #41: test_reward: -73.765000 Â± 67.471177, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #42: 10001it [00:02, 4424.09it/s, bastaushy/loss=109.333, env_step=420000, len=125, n/ep=7, n/st=1000, rew=37.43]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #42: test_reward: -68.715000 Â± 68.873535, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #43: 10001it [00:02, 4503.62it/s, bastaushy/loss=104.146, env_step=430000, len=136, n/ep=10, n/st=1000, rew=14.40]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #43: test_reward: -70.240000 Â± 67.312201, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #44: 10001it [00:02, 4434.59it/s, bastaushy/loss=102.324, env_step=440000, len=112, n/ep=12, n/st=1000, rew=-2.75]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #44: test_reward: -53.235000 Â± 79.543069, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #45: 10001it [00:02, 4444.05it/s, bastaushy/loss=99.173, env_step=450000, len=138, n/ep=6, n/st=1000, rew=-9.17]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #45: test_reward: -56.960000 Â± 77.177447, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #46: 10001it [00:02, 4650.15it/s, bastaushy/loss=98.205, env_step=460000, len=123, n/ep=8, n/st=1000, rew=45.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #46: test_reward: -61.940000 Â± 72.817899, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #47: 10001it [00:02, 4592.44it/s, bastaushy/loss=99.969, env_step=470000, len=108, n/ep=9, n/st=1000, rew=74.89]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #47: test_reward: -68.335000 Â± 69.903096, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #48: 10001it [00:02, 4582.55it/s, bastaushy/loss=98.948, env_step=480000, len=132, n/ep=13, n/st=1000, rew=9.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #48: test_reward: -66.425000 Â± 71.162521, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #49: 10001it [00:02, 4590.78it/s, bastaushy/loss=99.742, env_step=490000, len=133, n/ep=13, n/st=1000, rew=-3.69]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #49: test_reward: -57.555000 Â± 74.575579, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #50: 10001it [00:02, 4488.82it/s, bastaushy/loss=100.327, env_step=500000, len=112, n/ep=9, n/st=1000, rew=-11.89]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #50: test_reward: -74.395000 Â± 63.646594, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #51: 10001it [00:02, 4580.67it/s, bastaushy/loss=98.892, env_step=510000, len=106, n/ep=4, n/st=1000, rew=-3.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #51: test_reward: -75.275000 Â± 62.475030, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #52: 10001it [00:02, 4567.77it/s, bastaushy/loss=99.119, env_step=520000, len=102, n/ep=8, n/st=1000, rew=23.25]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #52: test_reward: -84.120000 Â± 53.356121, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #53: 10001it [00:02, 4513.73it/s, bastaushy/loss=98.730, env_step=530000, len=115, n/ep=12, n/st=1000, rew=50.17]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #53: test_reward: -78.160000 Â± 62.195855, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #54: 10001it [00:02, 4469.82it/s, bastaushy/loss=100.007, env_step=540000, len=127, n/ep=9, n/st=1000, rew=70.56]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #54: test_reward: -81.130000 Â± 57.312766, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #55: 10001it [00:02, 4514.02it/s, bastaushy/loss=102.171, env_step=550000, len=102, n/ep=10, n/st=1000, rew=1.50]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #55: test_reward: -73.670000 Â± 63.776101, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #56: 10001it [00:02, 4529.12it/s, bastaushy/loss=104.065, env_step=560000, len=135, n/ep=3, n/st=1000, rew=-40.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #56: test_reward: -70.880000 Â± 66.964659, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #57: 10001it [00:02, 4515.30it/s, bastaushy/loss=103.550, env_step=570000, len=136, n/ep=9, n/st=1000, rew=-12.67]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #57: test_reward: -81.665000 Â± 58.348974, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #58: 10001it [00:02, 4550.17it/s, bastaushy/loss=103.735, env_step=580000, len=147, n/ep=10, n/st=1000, rew=37.20]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #58: test_reward: -77.720000 Â± 60.129790, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #59: 10001it [00:02, 4493.41it/s, bastaushy/loss=102.778, env_step=590000, len=104, n/ep=10, n/st=1000, rew=19.90]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #59: test_reward: -77.015000 Â± 63.860823, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #60: 10001it [00:02, 4527.76it/s, bastaushy/loss=103.262, env_step=600000, len=141, n/ep=9, n/st=1000, rew=-33.22]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #60: test_reward: -79.750000 Â± 56.642718, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #61: 10001it [00:02, 4511.86it/s, bastaushy/loss=102.821, env_step=610000, len=145, n/ep=9, n/st=1000, rew=32.33]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #61: test_reward: -65.075000 Â± 72.645711, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #62: 10001it [00:02, 4506.41it/s, bastaushy/loss=102.196, env_step=620000, len=106, n/ep=6, n/st=1000, rew=-3.33]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #62: test_reward: -81.040000 Â± 58.509216, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #63: 10001it [00:02, 4420.55it/s, bastaushy/loss=101.109, env_step=630000, len=134, n/ep=7, n/st=1000, rew=20.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #63: test_reward: -64.670000 Â± 70.441118, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #64: 10001it [00:02, 4446.29it/s, bastaushy/loss=97.867, env_step=640000, len=120, n/ep=2, n/st=1000, rew=19.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #64: test_reward: -59.500000 Â± 74.808556, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #65: 10001it [00:02, 4422.69it/s, bastaushy/loss=97.440, env_step=650000, len=134, n/ep=6, n/st=1000, rew=57.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #65: test_reward: -74.260000 Â± 64.476836, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #66: 10001it [00:02, 4450.55it/s, bastaushy/loss=95.963, env_step=660000, len=137, n/ep=6, n/st=1000, rew=-58.50]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #66: test_reward: -65.210000 Â± 70.387470, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #67: 10001it [00:02, 4414.98it/s, bastaushy/loss=95.282, env_step=670000, len=146, n/ep=7, n/st=1000, rew=19.14]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #67: test_reward: -50.235000 Â± 77.505676, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #68: 10001it [00:02, 4475.44it/s, bastaushy/loss=95.392, env_step=680000, len=118, n/ep=7, n/st=1000, rew=62.71]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #68: test_reward: -56.860000 Â± 74.527716, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #69: 10001it [00:02, 4506.40it/s, bastaushy/loss=96.289, env_step=690000, len=138, n/ep=8, n/st=1000, rew=24.62]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #69: test_reward: -81.415000 Â± 53.873396, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #70: 10001it [00:02, 4257.20it/s, bastaushy/loss=96.582, env_step=700000, len=120, n/ep=12, n/st=1000, rew=30.42]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #70: test_reward: -72.420000 Â± 62.539776, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #71: 10001it [00:02, 4461.99it/s, bastaushy/loss=96.641, env_step=710000, len=121, n/ep=7, n/st=1000, rew=40.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #71: test_reward: -66.415000 Â± 73.740442, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #72: 10001it [00:02, 4472.81it/s, bastaushy/loss=96.263, env_step=720000, len=157, n/ep=8, n/st=1000, rew=-6.62]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #72: test_reward: -67.525000 Â± 69.929746, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #73: 10001it [00:02, 4492.56it/s, bastaushy/loss=96.914, env_step=730000, len=115, n/ep=5, n/st=1000, rew=20.20]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #73: test_reward: -71.375000 Â± 67.524546, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #74: 10001it [00:02, 4457.81it/s, bastaushy/loss=97.827, env_step=740000, len=120, n/ep=12, n/st=1000, rew=17.67]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #74: test_reward: -71.340000 Â± 66.746793, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #75: 10001it [00:02, 4490.70it/s, bastaushy/loss=96.883, env_step=750000, len=123, n/ep=11, n/st=1000, rew=21.91]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #75: test_reward: -82.775000 Â± 54.677275, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #76: 10001it [00:02, 4454.80it/s, bastaushy/loss=96.422, env_step=760000, len=100, n/ep=6, n/st=1000, rew=34.83]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #76: test_reward: -68.225000 Â± 69.306813, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #77: 10001it [00:02, 4491.12it/s, bastaushy/loss=96.624, env_step=770000, len=115, n/ep=14, n/st=1000, rew=26.57]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #77: test_reward: -74.365000 Â± 62.145489, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #78: 10001it [00:02, 4591.45it/s, bastaushy/loss=96.683, env_step=780000, len=124, n/ep=6, n/st=1000, rew=33.83]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #78: test_reward: -79.255000 Â± 58.611773, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #79: 10001it [00:02, 4573.86it/s, bastaushy/loss=95.151, env_step=790000, len=127, n/ep=10, n/st=1000, rew=-0.30]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #79: test_reward: -63.410000 Â± 72.112287, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #80: 10001it [00:02, 4489.49it/s, bastaushy/loss=93.542, env_step=800000, len=119, n/ep=8, n/st=1000, rew=-44.38]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #80: test_reward: -66.755000 Â± 71.305645, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #81: 10001it [00:02, 4594.03it/s, bastaushy/loss=92.791, env_step=810000, len=96, n/ep=9, n/st=1000, rew=12.22]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #81: test_reward: -80.375000 Â± 55.242324, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #82: 10001it [00:02, 4461.40it/s, bastaushy/loss=92.673, env_step=820000, len=109, n/ep=8, n/st=1000, rew=-2.12]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #82: test_reward: -63.100000 Â± 73.215504, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #83: 10001it [00:02, 4437.23it/s, bastaushy/loss=92.310, env_step=830000, len=117, n/ep=8, n/st=1000, rew=44.75]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #83: test_reward: -62.160000 Â± 75.392403, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #84: 10001it [00:02, 4467.13it/s, bastaushy/loss=91.697, env_step=840000, len=115, n/ep=5, n/st=1000, rew=-94.20]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #84: test_reward: -66.450000 Â± 68.966640, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #85: 10001it [00:02, 4529.19it/s, bastaushy/loss=91.452, env_step=850000, len=131, n/ep=10, n/st=1000, rew=18.70]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #85: test_reward: -73.730000 Â± 64.680346, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #86: 10001it [00:02, 4430.35it/s, bastaushy/loss=90.739, env_step=860000, len=107, n/ep=8, n/st=1000, rew=2.12]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #86: test_reward: -69.190000 Â± 69.024227, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #87: 10001it [00:02, 4491.27it/s, bastaushy/loss=89.597, env_step=870000, len=128, n/ep=9, n/st=1000, rew=8.56]                              \n","output_type":"stream"},{"name":"stdout","text":"Epoch #87: test_reward: -62.890000 Â± 73.366327, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #88: 10001it [00:02, 4439.32it/s, bastaushy/loss=87.755, env_step=880000, len=129, n/ep=8, n/st=1000, rew=2.50]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #88: test_reward: -74.170000 Â± 63.920741, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #89: 10001it [00:02, 4461.55it/s, bastaushy/loss=89.057, env_step=890000, len=118, n/ep=7, n/st=1000, rew=-34.86]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #89: test_reward: -69.430000 Â± 67.652976, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #90: 10001it [00:02, 4315.22it/s, bastaushy/loss=89.193, env_step=900000, len=150, n/ep=10, n/st=1000, rew=22.50]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #90: test_reward: -76.365000 Â± 60.706357, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #91: 10001it [00:02, 4462.24it/s, bastaushy/loss=89.338, env_step=910000, len=126, n/ep=6, n/st=1000, rew=60.67]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #91: test_reward: -48.955000 Â± 78.753178, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #92: 10001it [00:02, 4469.27it/s, bastaushy/loss=88.749, env_step=920000, len=137, n/ep=12, n/st=1000, rew=-25.67]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #92: test_reward: -57.155000 Â± 75.500669, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #93: 10001it [00:02, 4307.70it/s, bastaushy/loss=88.087, env_step=930000, len=109, n/ep=6, n/st=1000, rew=-33.17]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #93: test_reward: -47.490000 Â± 80.322039, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #94: 10001it [00:02, 4454.17it/s, bastaushy/loss=86.924, env_step=940000, len=151, n/ep=11, n/st=1000, rew=-11.18]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #94: test_reward: -34.250000 Â± 82.991912, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #95: 10001it [00:02, 4500.98it/s, bastaushy/loss=85.940, env_step=950000, len=131, n/ep=10, n/st=1000, rew=1.70]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #95: test_reward: -32.430000 Â± 84.377634, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #96: 10001it [00:02, 4342.49it/s, bastaushy/loss=86.772, env_step=960000, len=100, n/ep=10, n/st=1000, rew=20.10]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #96: test_reward: -29.085000 Â± 84.932372, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #97: 10001it [00:02, 4497.01it/s, bastaushy/loss=88.206, env_step=970000, len=102, n/ep=8, n/st=1000, rew=22.75]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #97: test_reward: -18.970000 Â± 87.236226, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #98: 10001it [00:02, 4556.11it/s, bastaushy/loss=88.449, env_step=980000, len=124, n/ep=10, n/st=1000, rew=56.40]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #98: test_reward: -46.310000 Â± 82.179340, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #99: 10001it [00:02, 4360.99it/s, bastaushy/loss=87.683, env_step=990000, len=92, n/ep=6, n/st=1000, rew=66.00]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #99: test_reward: -30.215000 Â± 86.200805, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #100: 10001it [00:02, 4569.53it/s, bastaushy/loss=87.185, env_step=1000000, len=140, n/ep=3, n/st=1000, rew=-27.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #100: test_reward: -41.975000 Â± 84.216651, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #101: 10001it [00:02, 4555.25it/s, bastaushy/loss=86.413, env_step=1010000, len=132, n/ep=15, n/st=1000, rew=10.27]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #101: test_reward: -33.515000 Â± 85.779309, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #102: 10001it [00:02, 4392.01it/s, bastaushy/loss=85.775, env_step=1020000, len=129, n/ep=4, n/st=1000, rew=6.50]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #102: test_reward: -50.340000 Â± 80.259232, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #103: 10001it [00:02, 4469.53it/s, bastaushy/loss=85.041, env_step=1030000, len=96, n/ep=8, n/st=1000, rew=70.50]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #103: test_reward: -55.915000 Â± 76.918449, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #104: 10001it [00:02, 4529.48it/s, bastaushy/loss=85.156, env_step=1040000, len=110, n/ep=12, n/st=1000, rew=1.67]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #104: test_reward: -24.855000 Â± 86.882300, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #105: 10001it [00:02, 4347.09it/s, bastaushy/loss=84.727, env_step=1050000, len=114, n/ep=9, n/st=1000, rew=30.56]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #105: test_reward: -35.010000 Â± 84.813029, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #106: 10001it [00:02, 4449.14it/s, bastaushy/loss=84.553, env_step=1060000, len=132, n/ep=7, n/st=1000, rew=41.29]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #106: test_reward: -53.365000 Â± 76.433512, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #107: 10001it [00:02, 4404.78it/s, bastaushy/loss=83.760, env_step=1070000, len=148, n/ep=8, n/st=1000, rew=69.50]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #107: test_reward: -65.375000 Â± 71.809988, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #108: 10001it [00:02, 4317.25it/s, bastaushy/loss=83.993, env_step=1080000, len=116, n/ep=8, n/st=1000, rew=-0.88]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #108: test_reward: -37.770000 Â± 85.766468, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #109: 10001it [00:02, 4404.17it/s, bastaushy/loss=83.037, env_step=1090000, len=141, n/ep=11, n/st=1000, rew=23.45]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #109: test_reward: -37.865000 Â± 87.994868, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #110: 10001it [00:02, 4434.75it/s, bastaushy/loss=82.790, env_step=1100000, len=137, n/ep=5, n/st=1000, rew=-56.20]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #110: test_reward: -36.005000 Â± 84.536530, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #111: 10001it [00:02, 4345.68it/s, bastaushy/loss=83.446, env_step=1110000, len=122, n/ep=14, n/st=1000, rew=-2.29]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #111: test_reward: -22.250000 Â± 88.320085, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #112: 10001it [00:02, 4471.59it/s, bastaushy/loss=85.067, env_step=1120000, len=118, n/ep=7, n/st=1000, rew=-13.71]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #112: test_reward: -59.565000 Â± 76.853144, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #113: 10001it [00:02, 4381.58it/s, bastaushy/loss=86.093, env_step=1130000, len=109, n/ep=10, n/st=1000, rew=2.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #113: test_reward: -47.635000 Â± 80.829894, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #114: 10001it [00:02, 4298.18it/s, bastaushy/loss=87.563, env_step=1140000, len=119, n/ep=7, n/st=1000, rew=12.29]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #114: test_reward: -63.905000 Â± 72.491765, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #115: 10001it [00:02, 4447.78it/s, bastaushy/loss=87.832, env_step=1150000, len=114, n/ep=7, n/st=1000, rew=17.14]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #115: test_reward: -46.680000 Â± 81.265784, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #116: 10001it [00:02, 4484.95it/s, bastaushy/loss=86.889, env_step=1160000, len=123, n/ep=8, n/st=1000, rew=47.88]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #116: test_reward: -27.950000 Â± 84.067101, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #117: 10001it [00:02, 4395.80it/s, bastaushy/loss=88.237, env_step=1170000, len=119, n/ep=8, n/st=1000, rew=70.75]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #117: test_reward: -47.980000 Â± 81.108998, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #118: 10001it [00:02, 4519.62it/s, bastaushy/loss=87.639, env_step=1180000, len=129, n/ep=10, n/st=1000, rew=1.50]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #118: test_reward: -21.455000 Â± 86.408090, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #119: 10001it [00:02, 4394.98it/s, bastaushy/loss=87.996, env_step=1190000, len=149, n/ep=8, n/st=1000, rew=22.25]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #119: test_reward: -48.320000 Â± 80.701472, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #120: 10001it [00:02, 4387.00it/s, bastaushy/loss=87.879, env_step=1200000, len=127, n/ep=10, n/st=1000, rew=-73.10]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #120: test_reward: -29.140000 Â± 86.729524, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #121: 10001it [00:02, 4418.02it/s, bastaushy/loss=88.470, env_step=1210000, len=81, n/ep=3, n/st=1000, rew=-35.67]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #121: test_reward: -47.915000 Â± 78.646028, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #122: 10001it [00:02, 4550.95it/s, bastaushy/loss=88.291, env_step=1220000, len=143, n/ep=9, n/st=1000, rew=11.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #122: test_reward: -28.020000 Â± 85.686928, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #123: 10001it [00:02, 4258.17it/s, bastaushy/loss=87.939, env_step=1230000, len=126, n/ep=12, n/st=1000, rew=15.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #123: test_reward: -56.745000 Â± 76.809635, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #124: 10001it [00:02, 4407.04it/s, bastaushy/loss=85.514, env_step=1240000, len=114, n/ep=7, n/st=1000, rew=15.43]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #124: test_reward: -51.675000 Â± 77.870401, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #125: 10001it [00:02, 4452.51it/s, bastaushy/loss=84.970, env_step=1250000, len=127, n/ep=9, n/st=1000, rew=48.89]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #125: test_reward: -34.030000 Â± 84.720771, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #126: 10001it [00:02, 4301.36it/s, bastaushy/loss=85.781, env_step=1260000, len=148, n/ep=7, n/st=1000, rew=9.86]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #126: test_reward: -32.490000 Â± 84.019164, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #127: 10001it [00:02, 4432.27it/s, bastaushy/loss=83.961, env_step=1270000, len=118, n/ep=7, n/st=1000, rew=18.43]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #127: test_reward: -31.545000 Â± 84.183953, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #128: 10001it [00:02, 4386.07it/s, bastaushy/loss=84.226, env_step=1280000, len=145, n/ep=10, n/st=1000, rew=23.90]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #128: test_reward: -33.855000 Â± 86.986171, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #129: 10001it [00:02, 4390.01it/s, bastaushy/loss=84.618, env_step=1290000, len=118, n/ep=11, n/st=1000, rew=-23.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #129: test_reward: -47.725000 Â± 79.890296, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #130: 10001it [00:02, 4425.04it/s, bastaushy/loss=82.981, env_step=1300000, len=114, n/ep=8, n/st=1000, rew=27.88]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #130: test_reward: -59.030000 Â± 75.339227, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #131: 10001it [00:02, 4501.44it/s, bastaushy/loss=81.729, env_step=1310000, len=167, n/ep=4, n/st=1000, rew=0.50]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #131: test_reward: -49.630000 Â± 80.283704, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #132: 10001it [00:02, 4434.33it/s, bastaushy/loss=80.994, env_step=1320000, len=135, n/ep=10, n/st=1000, rew=-1.30]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #132: test_reward: -54.960000 Â± 77.118016, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #133: 10001it [00:02, 4630.77it/s, bastaushy/loss=79.921, env_step=1330000, len=121, n/ep=9, n/st=1000, rew=34.78]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #133: test_reward: -38.905000 Â± 83.797410, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #134: 10001it [00:02, 4507.58it/s, bastaushy/loss=80.945, env_step=1340000, len=110, n/ep=7, n/st=1000, rew=-7.86]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #134: test_reward: -31.595000 Â± 85.006417, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #135: 10001it [00:02, 4429.59it/s, bastaushy/loss=80.647, env_step=1350000, len=109, n/ep=5, n/st=1000, rew=-3.60]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #135: test_reward: -41.825000 Â± 82.484267, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #136: 10001it [00:02, 4420.87it/s, bastaushy/loss=79.192, env_step=1360000, len=109, n/ep=11, n/st=1000, rew=-41.64]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #136: test_reward: -29.730000 Â± 87.371317, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #137: 10001it [00:02, 4440.80it/s, bastaushy/loss=79.448, env_step=1370000, len=93, n/ep=7, n/st=1000, rew=40.86]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #137: test_reward: -32.650000 Â± 86.005857, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #138: 10001it [00:02, 4505.40it/s, bastaushy/loss=78.482, env_step=1380000, len=89, n/ep=8, n/st=1000, rew=-28.38]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #138: test_reward: -22.825000 Â± 87.454356, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #139: 10001it [00:02, 4512.63it/s, bastaushy/loss=76.970, env_step=1390000, len=142, n/ep=13, n/st=1000, rew=1.85]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #139: test_reward: -31.070000 Â± 85.275701, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #140: 10001it [00:02, 4474.35it/s, bastaushy/loss=77.686, env_step=1400000, len=132, n/ep=7, n/st=1000, rew=13.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #140: test_reward: -40.785000 Â± 83.006016, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #141: 10001it [00:02, 4293.11it/s, bastaushy/loss=78.424, env_step=1410000, len=133, n/ep=7, n/st=1000, rew=35.29]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #141: test_reward: -36.415000 Â± 83.405412, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #142: 10001it [00:02, 4447.24it/s, bastaushy/loss=78.839, env_step=1420000, len=129, n/ep=12, n/st=1000, rew=32.83]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #142: test_reward: -20.985000 Â± 86.485286, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #143: 10001it [00:02, 4504.42it/s, bastaushy/loss=79.249, env_step=1430000, len=138, n/ep=8, n/st=1000, rew=19.88]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #143: test_reward: -39.405000 Â± 83.103435, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #144: 10001it [00:02, 4393.81it/s, bastaushy/loss=77.792, env_step=1440000, len=118, n/ep=10, n/st=1000, rew=59.70]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #144: test_reward: -21.830000 Â± 86.349760, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #145: 10001it [00:02, 4337.78it/s, bastaushy/loss=78.537, env_step=1450000, len=134, n/ep=8, n/st=1000, rew=48.62]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #145: test_reward: -42.770000 Â± 80.729778, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #146: 10001it [00:02, 4528.55it/s, bastaushy/loss=79.158, env_step=1460000, len=128, n/ep=10, n/st=1000, rew=-21.50]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #146: test_reward: -20.540000 Â± 88.916412, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #147: 10001it [00:02, 4421.25it/s, bastaushy/loss=77.226, env_step=1470000, len=108, n/ep=8, n/st=1000, rew=76.88]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #147: test_reward: -15.120000 Â± 87.481573, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #148: 10001it [00:02, 4509.60it/s, bastaushy/loss=76.921, env_step=1480000, len=126, n/ep=10, n/st=1000, rew=2.80]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #148: test_reward: -21.620000 Â± 86.873791, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #149: 10001it [00:02, 4428.38it/s, bastaushy/loss=76.392, env_step=1490000, len=102, n/ep=9, n/st=1000, rew=11.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #149: test_reward: -9.820000 Â± 88.147193, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #150: 10001it [00:02, 4483.13it/s, bastaushy/loss=77.255, env_step=1500000, len=131, n/ep=11, n/st=1000, rew=27.64]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #150: test_reward: -2.080000 Â± 87.904457, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #151: 10001it [00:02, 4462.68it/s, bastaushy/loss=76.493, env_step=1510000, len=118, n/ep=7, n/st=1000, rew=15.57]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #151: test_reward: -4.345000 Â± 87.292130, best_reward: -1.450000 Â± 86.758213 in #11\n","output_type":"stream"},{"name":"stderr","text":"Epoch #152: 10001it [00:02, 4420.40it/s, bastaushy/loss=75.579, env_step=1520000, len=125, n/ep=8, n/st=1000, rew=-19.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 50, 'qostaushy': 50}\nEpoch #152: test_reward: 15.680000 Â± 86.942726, best_reward: 15.680000 Â± 86.942726 in #152\n","output_type":"stream"},{"name":"stderr","text":"Epoch #153: 10001it [00:02, 4348.90it/s, bastaushy/loss=76.323, env_step=1530000, len=132, n/ep=10, n/st=1000, rew=41.40]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #153: test_reward: -9.630000 Â± 89.036358, best_reward: 15.680000 Â± 86.942726 in #152\n","output_type":"stream"},{"name":"stderr","text":"Epoch #154: 10001it [00:02, 4365.03it/s, bastaushy/loss=76.956, env_step=1540000, len=116, n/ep=12, n/st=1000, rew=20.58]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #154: test_reward: -16.840000 Â± 85.608612, best_reward: 15.680000 Â± 86.942726 in #152\n","output_type":"stream"},{"name":"stderr","text":"Epoch #155: 10001it [00:02, 4407.21it/s, bastaushy/loss=77.114, env_step=1550000, len=137, n/ep=7, n/st=1000, rew=35.43]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #155: test_reward: -3.135000 Â± 88.022592, best_reward: 15.680000 Â± 86.942726 in #152\n","output_type":"stream"},{"name":"stderr","text":"Epoch #156: 10001it [00:02, 4504.61it/s, bastaushy/loss=77.154, env_step=1560000, len=101, n/ep=7, n/st=1000, rew=14.43]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #156: test_reward: -46.960000 Â± 79.693465, best_reward: 15.680000 Â± 86.942726 in #152\n","output_type":"stream"},{"name":"stderr","text":"Epoch #157: 10001it [00:02, 4466.84it/s, bastaushy/loss=77.666, env_step=1570000, len=130, n/ep=6, n/st=1000, rew=-25.17]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #157: test_reward: -25.755000 Â± 85.431054, best_reward: 15.680000 Â± 86.942726 in #152\n","output_type":"stream"},{"name":"stderr","text":"Epoch #158: 10001it [00:02, 4440.85it/s, bastaushy/loss=78.111, env_step=1580000, len=129, n/ep=10, n/st=1000, rew=-21.70]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #158: test_reward: -28.850000 Â± 88.162733, best_reward: 15.680000 Â± 86.942726 in #152\n","output_type":"stream"},{"name":"stderr","text":"Epoch #159: 10001it [00:02, 4432.61it/s, bastaushy/loss=79.693, env_step=1590000, len=138, n/ep=6, n/st=1000, rew=30.33]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #159: test_reward: -53.235000 Â± 77.626991, best_reward: 15.680000 Â± 86.942726 in #152\n","output_type":"stream"},{"name":"stderr","text":"Epoch #160: 10001it [00:02, 4428.47it/s, bastaushy/loss=78.924, env_step=1600000, len=103, n/ep=7, n/st=1000, rew=-35.43]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #160: test_reward: 7.780000 Â± 90.644534, best_reward: 15.680000 Â± 86.942726 in #152\n","output_type":"stream"},{"name":"stderr","text":"Epoch #161: 10001it [00:02, 4469.46it/s, bastaushy/loss=80.038, env_step=1610000, len=129, n/ep=13, n/st=1000, rew=-6.08]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #161: test_reward: -3.390000 Â± 88.325749, best_reward: 15.680000 Â± 86.942726 in #152\n","output_type":"stream"},{"name":"stderr","text":"Epoch #162: 10001it [00:02, 4359.80it/s, bastaushy/loss=80.546, env_step=1620000, len=96, n/ep=6, n/st=1000, rew=94.83]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #162: test_reward: -20.780000 Â± 87.586252, best_reward: 15.680000 Â± 86.942726 in #152\n","output_type":"stream"},{"name":"stderr","text":"Epoch #163: 10001it [00:02, 4390.87it/s, bastaushy/loss=78.806, env_step=1630000, len=130, n/ep=7, n/st=1000, rew=-40.43]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #163: test_reward: -10.630000 Â± 88.555763, best_reward: 15.680000 Â± 86.942726 in #152\n","output_type":"stream"},{"name":"stderr","text":"Epoch #164: 10001it [00:02, 4352.15it/s, bastaushy/loss=79.352, env_step=1640000, len=127, n/ep=7, n/st=1000, rew=-11.29]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #164: test_reward: -34.870000 Â± 86.420039, best_reward: 15.680000 Â± 86.942726 in #152\n","output_type":"stream"},{"name":"stderr","text":"Epoch #165: 10001it [00:02, 4460.24it/s, bastaushy/loss=78.060, env_step=1650000, len=98, n/ep=6, n/st=1000, rew=96.33]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #165: test_reward: -16.115000 Â± 89.387369, best_reward: 15.680000 Â± 86.942726 in #152\n","output_type":"stream"},{"name":"stderr","text":"Epoch #166: 10001it [00:02, 4475.11it/s, bastaushy/loss=76.197, env_step=1660000, len=136, n/ep=6, n/st=1000, rew=34.83]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #166: test_reward: -24.145000 Â± 87.780601, best_reward: 15.680000 Â± 86.942726 in #152\n","output_type":"stream"},{"name":"stderr","text":"Epoch #167: 10001it [00:02, 4456.62it/s, bastaushy/loss=76.572, env_step=1670000, len=144, n/ep=5, n/st=1000, rew=57.80]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #167: test_reward: -0.595000 Â± 87.843730, best_reward: 15.680000 Â± 86.942726 in #152\n","output_type":"stream"},{"name":"stderr","text":"Epoch #168: 10001it [00:02, 4476.90it/s, bastaushy/loss=77.088, env_step=1680000, len=116, n/ep=10, n/st=1000, rew=54.30]                           \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 62, 'qostaushy': 38}\nEpoch #168: test_reward: 16.430000 Â± 85.201556, best_reward: 16.430000 Â± 85.201556 in #168\n","output_type":"stream"},{"name":"stderr","text":"Epoch #169: 10001it [00:02, 4462.35it/s, bastaushy/loss=76.640, env_step=1690000, len=140, n/ep=13, n/st=1000, rew=4.77]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #169: test_reward: 3.790000 Â± 89.466451, best_reward: 16.430000 Â± 85.201556 in #168\n","output_type":"stream"},{"name":"stderr","text":"Epoch #170: 10001it [00:02, 4407.95it/s, bastaushy/loss=75.508, env_step=1700000, len=138, n/ep=5, n/st=1000, rew=52.20]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #170: test_reward: -6.215000 Â± 91.356657, best_reward: 16.430000 Â± 85.201556 in #168\n","output_type":"stream"},{"name":"stderr","text":"Epoch #171: 10001it [00:02, 4334.76it/s, bastaushy/loss=74.113, env_step=1710000, len=119, n/ep=5, n/st=1000, rew=90.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #171: test_reward: -17.410000 Â± 88.690596, best_reward: 16.430000 Â± 85.201556 in #168\n","output_type":"stream"},{"name":"stderr","text":"Epoch #172: 10001it [00:02, 4359.26it/s, bastaushy/loss=71.845, env_step=1720000, len=113, n/ep=9, n/st=1000, rew=-22.11]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #172: test_reward: -27.500000 Â± 86.632442, best_reward: 16.430000 Â± 85.201556 in #168\n","output_type":"stream"},{"name":"stderr","text":"Epoch #173: 10001it [00:02, 4411.99it/s, bastaushy/loss=71.940, env_step=1730000, len=125, n/ep=7, n/st=1000, rew=23.14]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #173: test_reward: -18.925000 Â± 87.928206, best_reward: 16.430000 Â± 85.201556 in #168\n","output_type":"stream"},{"name":"stderr","text":"Epoch #174: 10001it [00:02, 4401.74it/s, bastaushy/loss=71.115, env_step=1740000, len=147, n/ep=5, n/st=1000, rew=16.20]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #174: test_reward: -22.725000 Â± 87.802445, best_reward: 16.430000 Â± 85.201556 in #168\n","output_type":"stream"},{"name":"stderr","text":"Epoch #175: 10001it [00:02, 4225.10it/s, bastaushy/loss=70.726, env_step=1750000, len=127, n/ep=8, n/st=1000, rew=70.38]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #175: test_reward: -12.560000 Â± 89.657160, best_reward: 16.430000 Â± 85.201556 in #168\n","output_type":"stream"},{"name":"stderr","text":"Epoch #176: 10001it [00:02, 4367.48it/s, bastaushy/loss=71.101, env_step=1760000, len=128, n/ep=8, n/st=1000, rew=-6.38]                           \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 55, 'qostaushy': 45}\nEpoch #176: test_reward: 16.770000 Â± 88.019868, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #177: 10001it [00:02, 4407.60it/s, bastaushy/loss=70.255, env_step=1770000, len=106, n/ep=11, n/st=1000, rew=28.91]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #177: test_reward: -27.515000 Â± 87.252563, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #178: 10001it [00:02, 4563.36it/s, bastaushy/loss=70.138, env_step=1780000, len=128, n/ep=15, n/st=1000, rew=-16.07]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #178: test_reward: -31.995000 Â± 86.144849, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #179: 10001it [00:02, 4564.57it/s, bastaushy/loss=70.703, env_step=1790000, len=108, n/ep=13, n/st=1000, rew=7.31]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #179: test_reward: -12.965000 Â± 90.310652, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #180: 10001it [00:02, 4600.71it/s, bastaushy/loss=72.211, env_step=1800000, len=164, n/ep=7, n/st=1000, rew=-12.14]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #180: test_reward: -19.220000 Â± 88.524356, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #181: 10001it [00:02, 4635.57it/s, bastaushy/loss=74.067, env_step=1810000, len=107, n/ep=8, n/st=1000, rew=22.12]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #181: test_reward: -18.530000 Â± 86.555930, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #182: 10001it [00:02, 4590.48it/s, bastaushy/loss=74.228, env_step=1820000, len=134, n/ep=5, n/st=1000, rew=50.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #182: test_reward: -6.380000 Â± 86.886855, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #183: 10001it [00:02, 4561.53it/s, bastaushy/loss=75.282, env_step=1830000, len=121, n/ep=15, n/st=1000, rew=8.73]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #183: test_reward: 14.305000 Â± 84.996364, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #184: 10001it [00:02, 4596.10it/s, bastaushy/loss=76.454, env_step=1840000, len=110, n/ep=8, n/st=1000, rew=32.50]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #184: test_reward: -6.475000 Â± 88.653479, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #185: 10001it [00:02, 4580.90it/s, bastaushy/loss=77.362, env_step=1850000, len=117, n/ep=8, n/st=1000, rew=-19.75]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #185: test_reward: -17.585000 Â± 88.832949, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #186: 10001it [00:02, 4642.69it/s, bastaushy/loss=79.062, env_step=1860000, len=141, n/ep=7, n/st=1000, rew=37.14]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #186: test_reward: -14.815000 Â± 88.839410, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #187: 10001it [00:02, 4667.24it/s, bastaushy/loss=79.427, env_step=1870000, len=132, n/ep=9, n/st=1000, rew=-9.67]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #187: test_reward: -8.470000 Â± 88.649755, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #188: 10001it [00:02, 4690.65it/s, bastaushy/loss=79.751, env_step=1880000, len=134, n/ep=9, n/st=1000, rew=-46.22]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #188: test_reward: -3.890000 Â± 88.953684, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #189: 10001it [00:02, 4707.01it/s, bastaushy/loss=79.051, env_step=1890000, len=122, n/ep=9, n/st=1000, rew=7.11]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #189: test_reward: -9.950000 Â± 88.677153, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #190: 10001it [00:02, 4608.74it/s, bastaushy/loss=77.735, env_step=1900000, len=114, n/ep=17, n/st=1000, rew=30.53]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #190: test_reward: -29.855000 Â± 87.488308, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #191: 10001it [00:02, 4646.09it/s, bastaushy/loss=76.380, env_step=1910000, len=111, n/ep=8, n/st=1000, rew=72.25]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #191: test_reward: 0.805000 Â± 91.373667, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #192: 10001it [00:02, 4751.26it/s, bastaushy/loss=76.854, env_step=1920000, len=130, n/ep=6, n/st=1000, rew=-60.83]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #192: test_reward: -15.295000 Â± 86.856709, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #193: 10001it [00:02, 4704.46it/s, bastaushy/loss=77.108, env_step=1930000, len=122, n/ep=11, n/st=1000, rew=41.09]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #193: test_reward: -10.665000 Â± 88.802493, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #194: 10001it [00:02, 4596.53it/s, bastaushy/loss=76.696, env_step=1940000, len=127, n/ep=7, n/st=1000, rew=62.86]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #194: test_reward: 3.945000 Â± 89.185212, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #195: 10001it [00:02, 4678.62it/s, bastaushy/loss=76.273, env_step=1950000, len=127, n/ep=6, n/st=1000, rew=2.17]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #195: test_reward: -9.910000 Â± 88.689131, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #196: 10001it [00:02, 4650.46it/s, bastaushy/loss=75.374, env_step=1960000, len=131, n/ep=9, n/st=1000, rew=-18.33]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #196: test_reward: 10.765000 Â± 86.393691, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #197: 10001it [00:02, 4691.61it/s, bastaushy/loss=76.170, env_step=1970000, len=140, n/ep=10, n/st=1000, rew=76.20]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #197: test_reward: -9.015000 Â± 89.183938, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #198: 10001it [00:02, 4085.06it/s, bastaushy/loss=75.100, env_step=1980000, len=117, n/ep=12, n/st=1000, rew=32.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #198: test_reward: -38.135000 Â± 84.984627, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #199: 10001it [00:02, 4568.81it/s, bastaushy/loss=75.159, env_step=1990000, len=129, n/ep=7, n/st=1000, rew=20.14]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #199: test_reward: -34.890000 Â± 83.144741, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #200: 10001it [00:02, 4526.35it/s, bastaushy/loss=75.628, env_step=2000000, len=134, n/ep=8, n/st=1000, rew=-1.25]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #200: test_reward: 9.305000 Â± 88.911878, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #201: 10001it [00:02, 4488.81it/s, bastaushy/loss=76.469, env_step=2010000, len=118, n/ep=8, n/st=1000, rew=68.62]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #201: test_reward: -23.060000 Â± 88.352852, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #202: 10001it [00:02, 4537.97it/s, bastaushy/loss=76.420, env_step=2020000, len=124, n/ep=12, n/st=1000, rew=-0.08]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #202: test_reward: -34.895000 Â± 85.074638, best_reward: 16.770000 Â± 88.019868 in #176\n","output_type":"stream"},{"name":"stderr","text":"Epoch #203: 10001it [00:02, 4578.60it/s, bastaushy/loss=75.149, env_step=2030000, len=131, n/ep=5, n/st=1000, rew=53.40]                             \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 43, 'qostaushy': 57}\nEpoch #203: test_reward: 17.850000 Â± 85.630529, best_reward: 17.850000 Â± 85.630529 in #203\n","output_type":"stream"},{"name":"stderr","text":"Epoch #204: 10001it [00:02, 4594.75it/s, bastaushy/loss=73.326, env_step=2040000, len=93, n/ep=7, n/st=1000, rew=34.57]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #204: test_reward: -1.595000 Â± 89.921082, best_reward: 17.850000 Â± 85.630529 in #203\n","output_type":"stream"},{"name":"stderr","text":"Epoch #205: 10001it [00:02, 4615.49it/s, bastaushy/loss=72.898, env_step=2050000, len=119, n/ep=9, n/st=1000, rew=49.22]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #205: test_reward: -15.945000 Â± 87.797619, best_reward: 17.850000 Â± 85.630529 in #203\n","output_type":"stream"},{"name":"stderr","text":"Epoch #206: 10001it [00:02, 4611.93it/s, bastaushy/loss=73.155, env_step=2060000, len=114, n/ep=11, n/st=1000, rew=5.91]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #206: test_reward: -8.985000 Â± 88.774798, best_reward: 17.850000 Â± 85.630529 in #203\n","output_type":"stream"},{"name":"stderr","text":"Epoch #207: 10001it [00:02, 4553.26it/s, bastaushy/loss=71.437, env_step=2070000, len=150, n/ep=3, n/st=1000, rew=88.33]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #207: test_reward: -5.240000 Â± 91.249890, best_reward: 17.850000 Â± 85.630529 in #203\n","output_type":"stream"},{"name":"stderr","text":"Epoch #208: 10001it [00:02, 4458.41it/s, bastaushy/loss=69.963, env_step=2080000, len=137, n/ep=7, n/st=1000, rew=37.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #208: test_reward: -19.320000 Â± 89.277923, best_reward: 17.850000 Â± 85.630529 in #203\n","output_type":"stream"},{"name":"stderr","text":"Epoch #209: 10001it [00:02, 4616.93it/s, bastaushy/loss=68.479, env_step=2090000, len=122, n/ep=6, n/st=1000, rew=-3.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #209: test_reward: 1.725000 Â± 88.512143, best_reward: 17.850000 Â± 85.630529 in #203\n","output_type":"stream"},{"name":"stderr","text":"Epoch #210: 10001it [00:02, 4623.99it/s, bastaushy/loss=67.666, env_step=2100000, len=118, n/ep=11, n/st=1000, rew=-26.18]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #210: test_reward: -9.160000 Â± 88.894625, best_reward: 17.850000 Â± 85.630529 in #203\n","output_type":"stream"},{"name":"stderr","text":"Epoch #211: 10001it [00:02, 4696.51it/s, bastaushy/loss=66.233, env_step=2110000, len=119, n/ep=12, n/st=1000, rew=30.58]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #211: test_reward: -26.605000 Â± 87.205212, best_reward: 17.850000 Â± 85.630529 in #203\n","output_type":"stream"},{"name":"stderr","text":"Epoch #212: 10001it [00:02, 4656.64it/s, bastaushy/loss=66.628, env_step=2120000, len=116, n/ep=10, n/st=1000, rew=38.80]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #212: test_reward: -20.280000 Â± 89.848381, best_reward: 17.850000 Â± 85.630529 in #203\n","output_type":"stream"},{"name":"stderr","text":"Epoch #213: 10001it [00:02, 4649.34it/s, bastaushy/loss=66.771, env_step=2130000, len=109, n/ep=10, n/st=1000, rew=58.60]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #213: test_reward: -0.740000 Â± 89.816549, best_reward: 17.850000 Â± 85.630529 in #203\n","output_type":"stream"},{"name":"stderr","text":"Epoch #214: 10001it [00:02, 4696.65it/s, bastaushy/loss=68.570, env_step=2140000, len=128, n/ep=7, n/st=1000, rew=42.86]                            \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 59, 'qostaushy': 41}\nEpoch #214: test_reward: 19.120000 Â± 86.293891, best_reward: 19.120000 Â± 86.293891 in #214\n","output_type":"stream"},{"name":"stderr","text":"Epoch #215: 10001it [00:02, 4414.31it/s, bastaushy/loss=69.348, env_step=2150000, len=113, n/ep=6, n/st=1000, rew=6.17]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #215: test_reward: -2.650000 Â± 92.120288, best_reward: 19.120000 Â± 86.293891 in #214\n","output_type":"stream"},{"name":"stderr","text":"Epoch #216: 10001it [00:02, 4567.74it/s, bastaushy/loss=68.793, env_step=2160000, len=101, n/ep=6, n/st=1000, rew=65.33]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #216: test_reward: -16.080000 Â± 88.982884, best_reward: 19.120000 Â± 86.293891 in #214\n","output_type":"stream"},{"name":"stderr","text":"Epoch #217: 10001it [00:02, 4614.96it/s, bastaushy/loss=69.206, env_step=2170000, len=93, n/ep=5, n/st=1000, rew=62.40]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #217: test_reward: 2.070000 Â± 89.850905, best_reward: 19.120000 Â± 86.293891 in #214\n","output_type":"stream"},{"name":"stderr","text":"Epoch #218: 10001it [00:02, 4406.69it/s, bastaushy/loss=70.087, env_step=2180000, len=109, n/ep=9, n/st=1000, rew=10.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #218: test_reward: 4.540000 Â± 90.813096, best_reward: 19.120000 Â± 86.293891 in #214\n","output_type":"stream"},{"name":"stderr","text":"Epoch #219: 10001it [00:02, 4591.65it/s, bastaushy/loss=71.120, env_step=2190000, len=94, n/ep=5, n/st=1000, rew=-17.80]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #219: test_reward: 3.730000 Â± 89.428726, best_reward: 19.120000 Â± 86.293891 in #214\n","output_type":"stream"},{"name":"stderr","text":"Epoch #220: 10001it [00:02, 4576.35it/s, bastaushy/loss=71.279, env_step=2200000, len=127, n/ep=11, n/st=1000, rew=21.91]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #220: test_reward: -11.350000 Â± 88.925798, best_reward: 19.120000 Â± 86.293891 in #214\n","output_type":"stream"},{"name":"stderr","text":"Epoch #221: 10001it [00:02, 4474.82it/s, bastaushy/loss=69.733, env_step=2210000, len=132, n/ep=9, n/st=1000, rew=34.67]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #221: test_reward: 6.570000 Â± 88.944056, best_reward: 19.120000 Â± 86.293891 in #214\n","output_type":"stream"},{"name":"stderr","text":"Epoch #222: 10001it [00:02, 4568.76it/s, bastaushy/loss=69.668, env_step=2220000, len=101, n/ep=9, n/st=1000, rew=32.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #222: test_reward: 0.875000 Â± 89.687398, best_reward: 19.120000 Â± 86.293891 in #214\n","output_type":"stream"},{"name":"stderr","text":"Epoch #223: 10001it [00:02, 4637.94it/s, bastaushy/loss=69.584, env_step=2230000, len=119, n/ep=7, n/st=1000, rew=92.71]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #223: test_reward: -8.850000 Â± 89.548520, best_reward: 19.120000 Â± 86.293891 in #214\n","output_type":"stream"},{"name":"stderr","text":"Epoch #224: 10001it [00:02, 4622.19it/s, bastaushy/loss=69.167, env_step=2240000, len=116, n/ep=4, n/st=1000, rew=95.25]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #224: test_reward: -6.205000 Â± 89.540119, best_reward: 19.120000 Â± 86.293891 in #214\n","output_type":"stream"},{"name":"stderr","text":"Epoch #225: 10001it [00:02, 4501.04it/s, bastaushy/loss=68.942, env_step=2250000, len=97, n/ep=5, n/st=1000, rew=-15.60]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #225: test_reward: 5.325000 Â± 88.878059, best_reward: 19.120000 Â± 86.293891 in #214\n","output_type":"stream"},{"name":"stderr","text":"Epoch #226: 10001it [00:02, 4579.94it/s, bastaushy/loss=69.899, env_step=2260000, len=118, n/ep=10, n/st=1000, rew=3.70]                            \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 59, 'qostaushy': 41}\nEpoch #226: test_reward: 22.510000 Â± 85.844918, best_reward: 22.510000 Â± 85.844918 in #226\n","output_type":"stream"},{"name":"stderr","text":"Epoch #227: 10001it [00:02, 4482.43it/s, bastaushy/loss=69.938, env_step=2270000, len=108, n/ep=6, n/st=1000, rew=-4.67]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #227: test_reward: 5.095000 Â± 88.939507, best_reward: 22.510000 Â± 85.844918 in #226\n","output_type":"stream"},{"name":"stderr","text":"Epoch #228: 10001it [00:02, 4577.68it/s, bastaushy/loss=70.664, env_step=2280000, len=112, n/ep=8, n/st=1000, rew=73.88]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #228: test_reward: 18.445000 Â± 87.429955, best_reward: 22.510000 Â± 85.844918 in #226\n","output_type":"stream"},{"name":"stderr","text":"Epoch #229: 10001it [00:02, 4535.29it/s, bastaushy/loss=70.782, env_step=2290000, len=129, n/ep=7, n/st=1000, rew=42.86]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #229: test_reward: -2.410000 Â± 89.090975, best_reward: 22.510000 Â± 85.844918 in #226\n","output_type":"stream"},{"name":"stderr","text":"Epoch #230: 10001it [00:02, 4636.52it/s, bastaushy/loss=71.122, env_step=2300000, len=142, n/ep=9, n/st=1000, rew=31.89]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #230: test_reward: 11.745000 Â± 88.837830, best_reward: 22.510000 Â± 85.844918 in #226\n","output_type":"stream"},{"name":"stderr","text":"Epoch #231: 10001it [00:02, 4610.03it/s, bastaushy/loss=72.628, env_step=2310000, len=109, n/ep=5, n/st=1000, rew=-9.80]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #231: test_reward: -6.785000 Â± 88.068262, best_reward: 22.510000 Â± 85.844918 in #226\n","output_type":"stream"},{"name":"stderr","text":"Epoch #232: 10001it [00:02, 4578.69it/s, bastaushy/loss=72.851, env_step=2320000, len=110, n/ep=9, n/st=1000, rew=12.56]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #232: test_reward: -4.155000 Â± 88.392822, best_reward: 22.510000 Â± 85.844918 in #226\n","output_type":"stream"},{"name":"stderr","text":"Epoch #233: 10001it [00:02, 4527.44it/s, bastaushy/loss=73.444, env_step=2330000, len=108, n/ep=10, n/st=1000, rew=73.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #233: test_reward: 3.675000 Â± 87.369842, best_reward: 22.510000 Â± 85.844918 in #226\n","output_type":"stream"},{"name":"stderr","text":"Epoch #234: 10001it [00:02, 4615.36it/s, bastaushy/loss=73.022, env_step=2340000, len=126, n/ep=2, n/st=1000, rew=95.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #234: test_reward: 13.895000 Â± 89.451126, best_reward: 22.510000 Â± 85.844918 in #226\n","output_type":"stream"},{"name":"stderr","text":"Epoch #235: 10001it [00:02, 4615.10it/s, bastaushy/loss=74.643, env_step=2350000, len=119, n/ep=6, n/st=1000, rew=4.00]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #235: test_reward: 21.810000 Â± 87.425419, best_reward: 22.510000 Â± 85.844918 in #226\n","output_type":"stream"},{"name":"stderr","text":"Epoch #236: 10001it [00:02, 4482.95it/s, bastaushy/loss=74.946, env_step=2360000, len=139, n/ep=9, n/st=1000, rew=49.44]                           \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 62, 'qostaushy': 38}\nEpoch #236: test_reward: 24.375000 Â± 85.785164, best_reward: 24.375000 Â± 85.785164 in #236\n","output_type":"stream"},{"name":"stderr","text":"Epoch #237: 10001it [00:02, 4687.99it/s, bastaushy/loss=75.808, env_step=2370000, len=100, n/ep=11, n/st=1000, rew=45.64]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #237: test_reward: -0.090000 Â± 90.215974, best_reward: 24.375000 Â± 85.785164 in #236\n","output_type":"stream"},{"name":"stderr","text":"Epoch #238: 10001it [00:02, 4616.15it/s, bastaushy/loss=76.493, env_step=2380000, len=132, n/ep=8, n/st=1000, rew=30.88]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #238: test_reward: -0.630000 Â± 90.827986, best_reward: 24.375000 Â± 85.785164 in #236\n","output_type":"stream"},{"name":"stderr","text":"Epoch #239: 10001it [00:02, 4636.39it/s, bastaushy/loss=77.645, env_step=2390000, len=121, n/ep=10, n/st=1000, rew=5.90]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #239: test_reward: 4.350000 Â± 87.614197, best_reward: 24.375000 Â± 85.785164 in #236\n","output_type":"stream"},{"name":"stderr","text":"Epoch #240: 10001it [00:02, 4473.64it/s, bastaushy/loss=79.805, env_step=2400000, len=118, n/ep=7, n/st=1000, rew=67.29]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #240: test_reward: -5.520000 Â± 90.143938, best_reward: 24.375000 Â± 85.785164 in #236\n","output_type":"stream"},{"name":"stderr","text":"Epoch #241: 10001it [00:02, 4620.27it/s, bastaushy/loss=81.376, env_step=2410000, len=127, n/ep=7, n/st=1000, rew=14.71]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #241: test_reward: 10.745000 Â± 87.717102, best_reward: 24.375000 Â± 85.785164 in #236\n","output_type":"stream"},{"name":"stderr","text":"Epoch #242: 10001it [00:02, 4567.22it/s, bastaushy/loss=81.705, env_step=2420000, len=116, n/ep=4, n/st=1000, rew=37.50]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #242: test_reward: 5.445000 Â± 88.731657, best_reward: 24.375000 Â± 85.785164 in #236\n","output_type":"stream"},{"name":"stderr","text":"Epoch #243: 10001it [00:02, 4560.83it/s, bastaushy/loss=81.884, env_step=2430000, len=118, n/ep=9, n/st=1000, rew=-51.33]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #243: test_reward: -7.290000 Â± 90.314926, best_reward: 24.375000 Â± 85.785164 in #236\n","output_type":"stream"},{"name":"stderr","text":"Epoch #244: 10001it [00:02, 4635.16it/s, bastaushy/loss=82.247, env_step=2440000, len=122, n/ep=7, n/st=1000, rew=40.43]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #244: test_reward: 10.190000 Â± 88.870827, best_reward: 24.375000 Â± 85.785164 in #236\n","output_type":"stream"},{"name":"stderr","text":"Epoch #245: 10001it [00:02, 4592.88it/s, bastaushy/loss=80.506, env_step=2450000, len=129, n/ep=10, n/st=1000, rew=14.10]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #245: test_reward: 17.085000 Â± 87.328219, best_reward: 24.375000 Â± 85.785164 in #236\n","output_type":"stream"},{"name":"stderr","text":"Epoch #246: 10001it [00:02, 4601.90it/s, bastaushy/loss=79.245, env_step=2460000, len=114, n/ep=7, n/st=1000, rew=68.14]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #246: test_reward: 9.050000 Â± 89.018130, best_reward: 24.375000 Â± 85.785164 in #236\n","output_type":"stream"},{"name":"stderr","text":"Epoch #247: 10001it [00:02, 4238.02it/s, bastaushy/loss=79.252, env_step=2470000, len=109, n/ep=8, n/st=1000, rew=26.75]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #247: test_reward: -1.515000 Â± 91.177682, best_reward: 24.375000 Â± 85.785164 in #236\n","output_type":"stream"},{"name":"stderr","text":"Epoch #248: 10001it [00:02, 4506.38it/s, bastaushy/loss=78.408, env_step=2480000, len=127, n/ep=8, n/st=1000, rew=44.50]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #248: test_reward: 17.965000 Â± 86.704232, best_reward: 24.375000 Â± 85.785164 in #236\n","output_type":"stream"},{"name":"stderr","text":"Epoch #249: 10001it [00:02, 4623.22it/s, bastaushy/loss=77.034, env_step=2490000, len=122, n/ep=15, n/st=1000, rew=30.53]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #249: test_reward: 14.475000 Â± 87.618716, best_reward: 24.375000 Â± 85.785164 in #236\n","output_type":"stream"},{"name":"stderr","text":"Epoch #250: 10001it [00:02, 4617.24it/s, bastaushy/loss=75.385, env_step=2500000, len=101, n/ep=5, n/st=1000, rew=53.60]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #250: test_reward: 5.460000 Â± 89.421409, best_reward: 24.375000 Â± 85.785164 in #236\n","output_type":"stream"},{"name":"stderr","text":"Epoch #251: 10001it [00:02, 4598.24it/s, bastaushy/loss=74.236, env_step=2510000, len=131, n/ep=11, n/st=1000, rew=-7.18]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #251: test_reward: 22.030000 Â± 86.134773, best_reward: 24.375000 Â± 85.785164 in #236\n","output_type":"stream"},{"name":"stderr","text":"Epoch #252: 10001it [00:02, 4632.74it/s, bastaushy/loss=74.520, env_step=2520000, len=115, n/ep=5, n/st=1000, rew=21.60]                            \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 65, 'qostaushy': 35}\nEpoch #252: test_reward: 29.765000 Â± 84.006010, best_reward: 29.765000 Â± 84.006010 in #252\n","output_type":"stream"},{"name":"stderr","text":"Epoch #253: 10001it [00:02, 4574.15it/s, bastaushy/loss=75.004, env_step=2530000, len=112, n/ep=9, n/st=1000, rew=8.44]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #253: test_reward: 21.480000 Â± 85.026052, best_reward: 29.765000 Â± 84.006010 in #252\n","output_type":"stream"},{"name":"stderr","text":"Epoch #254: 10001it [00:02, 4396.83it/s, bastaushy/loss=76.442, env_step=2540000, len=127, n/ep=6, n/st=1000, rew=34.17]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #254: test_reward: 16.070000 Â± 85.926859, best_reward: 29.765000 Â± 84.006010 in #252\n","output_type":"stream"},{"name":"stderr","text":"Epoch #255: 10001it [00:02, 4272.86it/s, bastaushy/loss=76.659, env_step=2550000, len=114, n/ep=10, n/st=1000, rew=-38.20]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #255: test_reward: 25.120000 Â± 84.977148, best_reward: 29.765000 Â± 84.006010 in #252\n","output_type":"stream"},{"name":"stderr","text":"Epoch #256: 10001it [00:02, 4471.65it/s, bastaushy/loss=77.969, env_step=2560000, len=112, n/ep=6, n/st=1000, rew=32.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #256: test_reward: 9.900000 Â± 86.970512, best_reward: 29.765000 Â± 84.006010 in #252\n","output_type":"stream"},{"name":"stderr","text":"Epoch #257: 10001it [00:02, 4463.78it/s, bastaushy/loss=77.995, env_step=2570000, len=124, n/ep=7, n/st=1000, rew=14.43]                            \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 70, 'qostaushy': 30}\nEpoch #257: test_reward: 50.870000 Â± 72.843003, best_reward: 50.870000 Â± 72.843003 in #257\n","output_type":"stream"},{"name":"stderr","text":"Epoch #258: 10001it [00:02, 4571.27it/s, bastaushy/loss=77.781, env_step=2580000, len=120, n/ep=7, n/st=1000, rew=8.71]                            \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 65, 'qostaushy': 35}\nEpoch #258: test_reward: 55.940000 Â± 68.757737, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #259: 10001it [00:02, 4553.41it/s, bastaushy/loss=79.071, env_step=2590000, len=83, n/ep=6, n/st=1000, rew=31.17]                              \n","output_type":"stream"},{"name":"stdout","text":"Epoch #259: test_reward: 7.110000 Â± 89.673786, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #260: 10001it [00:02, 4524.87it/s, bastaushy/loss=80.131, env_step=2600000, len=127, n/ep=5, n/st=1000, rew=53.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #260: test_reward: 23.705000 Â± 86.880251, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #261: 10001it [00:02, 4559.03it/s, bastaushy/loss=79.621, env_step=2610000, len=110, n/ep=11, n/st=1000, rew=25.82]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #261: test_reward: 24.915000 Â± 84.706421, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #262: 10001it [00:02, 4616.92it/s, bastaushy/loss=79.421, env_step=2620000, len=125, n/ep=14, n/st=1000, rew=8.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #262: test_reward: 36.730000 Â± 79.518156, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #263: 10001it [00:02, 4588.21it/s, bastaushy/loss=79.566, env_step=2630000, len=119, n/ep=9, n/st=1000, rew=34.67]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #263: test_reward: 5.325000 Â± 88.316303, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #264: 10001it [00:02, 4535.18it/s, bastaushy/loss=76.993, env_step=2640000, len=103, n/ep=10, n/st=1000, rew=-19.40]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #264: test_reward: 29.220000 Â± 81.777635, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #265: 10001it [00:02, 4529.38it/s, bastaushy/loss=76.785, env_step=2650000, len=122, n/ep=9, n/st=1000, rew=8.33]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #265: test_reward: 24.250000 Â± 86.243362, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #266: 10001it [00:02, 4595.28it/s, bastaushy/loss=76.556, env_step=2660000, len=115, n/ep=10, n/st=1000, rew=23.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #266: test_reward: 32.400000 Â± 84.008809, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #267: 10001it [00:02, 4577.38it/s, bastaushy/loss=76.143, env_step=2670000, len=117, n/ep=9, n/st=1000, rew=31.56]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #267: test_reward: 31.875000 Â± 82.974149, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #268: 10001it [00:02, 4493.55it/s, bastaushy/loss=77.284, env_step=2680000, len=125, n/ep=4, n/st=1000, rew=-1.75]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #268: test_reward: 6.125000 Â± 87.828978, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #269: 10001it [00:02, 4498.37it/s, bastaushy/loss=77.679, env_step=2690000, len=139, n/ep=6, n/st=1000, rew=-31.67]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #269: test_reward: 41.010000 Â± 79.411334, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #270: 10001it [00:02, 4532.18it/s, bastaushy/loss=76.546, env_step=2700000, len=128, n/ep=8, n/st=1000, rew=69.38]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #270: test_reward: 21.595000 Â± 86.592615, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #271: 10001it [00:02, 4625.25it/s, bastaushy/loss=77.311, env_step=2710000, len=129, n/ep=6, n/st=1000, rew=-0.33]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #271: test_reward: 12.630000 Â± 89.249891, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #272: 10001it [00:02, 4576.46it/s, bastaushy/loss=76.183, env_step=2720000, len=116, n/ep=4, n/st=1000, rew=96.50]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #272: test_reward: 19.045000 Â± 84.051609, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #273: 10001it [00:02, 4585.95it/s, bastaushy/loss=75.164, env_step=2730000, len=115, n/ep=9, n/st=1000, rew=31.56]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #273: test_reward: 17.050000 Â± 88.028220, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #274: 10001it [00:02, 4569.51it/s, bastaushy/loss=76.174, env_step=2740000, len=130, n/ep=11, n/st=1000, rew=28.82]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #274: test_reward: 18.055000 Â± 86.846025, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #275: 10001it [00:02, 4556.92it/s, bastaushy/loss=75.909, env_step=2750000, len=132, n/ep=11, n/st=1000, rew=27.55]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #275: test_reward: 45.315000 Â± 73.319000, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #276: 10001it [00:02, 4586.60it/s, bastaushy/loss=76.782, env_step=2760000, len=115, n/ep=7, n/st=1000, rew=12.71]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #276: test_reward: 21.220000 Â± 88.264611, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #277: 10001it [00:02, 4509.68it/s, bastaushy/loss=75.999, env_step=2770000, len=116, n/ep=10, n/st=1000, rew=37.10]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #277: test_reward: 27.290000 Â± 84.086776, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #278: 10001it [00:02, 4585.35it/s, bastaushy/loss=74.723, env_step=2780000, len=128, n/ep=10, n/st=1000, rew=56.50]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #278: test_reward: -12.975000 Â± 88.698390, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #279: 10001it [00:02, 4639.85it/s, bastaushy/loss=73.514, env_step=2790000, len=108, n/ep=8, n/st=1000, rew=-26.25]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #279: test_reward: 22.915000 Â± 85.049267, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #280: 10001it [00:02, 4589.64it/s, bastaushy/loss=74.344, env_step=2800000, len=130, n/ep=7, n/st=1000, rew=14.29]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #280: test_reward: 10.135000 Â± 90.174147, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #281: 10001it [00:02, 4580.07it/s, bastaushy/loss=74.344, env_step=2810000, len=114, n/ep=9, n/st=1000, rew=30.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #281: test_reward: 26.690000 Â± 84.090094, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #282: 10001it [00:02, 4654.37it/s, bastaushy/loss=76.391, env_step=2820000, len=150, n/ep=6, n/st=1000, rew=-2.33]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #282: test_reward: 4.925000 Â± 89.910841, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #283: 10001it [00:02, 4617.12it/s, bastaushy/loss=77.706, env_step=2830000, len=141, n/ep=6, n/st=1000, rew=32.33]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #283: test_reward: 19.740000 Â± 86.868075, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #284: 10001it [00:02, 4531.92it/s, bastaushy/loss=79.278, env_step=2840000, len=98, n/ep=9, n/st=1000, rew=11.33]                              \n","output_type":"stream"},{"name":"stdout","text":"Epoch #284: test_reward: 0.735000 Â± 90.626126, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #285: 10001it [00:02, 4544.15it/s, bastaushy/loss=80.463, env_step=2850000, len=116, n/ep=9, n/st=1000, rew=-11.78]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #285: test_reward: 26.885000 Â± 83.569921, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #286: 10001it [00:02, 4612.26it/s, bastaushy/loss=79.889, env_step=2860000, len=120, n/ep=5, n/st=1000, rew=57.20]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #286: test_reward: 35.055000 Â± 80.317507, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #287: 10001it [00:02, 4607.30it/s, bastaushy/loss=79.981, env_step=2870000, len=114, n/ep=5, n/st=1000, rew=56.20]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #287: test_reward: 45.195000 Â± 78.088264, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #288: 10001it [00:02, 4429.51it/s, bastaushy/loss=79.923, env_step=2880000, len=99, n/ep=5, n/st=1000, rew=65.40]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #288: test_reward: 23.705000 Â± 87.101883, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #289: 10001it [00:02, 4579.84it/s, bastaushy/loss=80.458, env_step=2890000, len=140, n/ep=11, n/st=1000, rew=11.18]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #289: test_reward: 29.095000 Â± 82.754915, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #290: 10001it [00:02, 4647.32it/s, bastaushy/loss=79.993, env_step=2900000, len=137, n/ep=9, n/st=1000, rew=32.67]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #290: test_reward: 29.025000 Â± 81.569690, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #291: 10001it [00:02, 4484.03it/s, bastaushy/loss=80.025, env_step=2910000, len=121, n/ep=10, n/st=1000, rew=19.60]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #291: test_reward: 7.350000 Â± 89.268682, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #292: 10001it [00:02, 4557.49it/s, bastaushy/loss=79.252, env_step=2920000, len=121, n/ep=13, n/st=1000, rew=11.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #292: test_reward: 25.770000 Â± 85.095224, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #293: 10001it [00:02, 4536.26it/s, bastaushy/loss=78.335, env_step=2930000, len=95, n/ep=9, n/st=1000, rew=15.89]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #293: test_reward: 36.255000 Â± 80.951467, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #294: 10001it [00:02, 4495.47it/s, bastaushy/loss=76.540, env_step=2940000, len=121, n/ep=10, n/st=1000, rew=38.50]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #294: test_reward: 20.365000 Â± 83.944337, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #295: 10001it [00:02, 4571.80it/s, bastaushy/loss=76.569, env_step=2950000, len=127, n/ep=11, n/st=1000, rew=29.55]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #295: test_reward: 22.150000 Â± 88.225946, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #296: 10001it [00:02, 4384.86it/s, bastaushy/loss=75.800, env_step=2960000, len=115, n/ep=7, n/st=1000, rew=-10.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #296: test_reward: 37.240000 Â± 81.524183, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #297: 10001it [00:02, 4403.52it/s, bastaushy/loss=76.502, env_step=2970000, len=111, n/ep=10, n/st=1000, rew=53.40]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #297: test_reward: 35.385000 Â± 80.335837, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #298: 10001it [00:02, 4482.28it/s, bastaushy/loss=77.801, env_step=2980000, len=131, n/ep=13, n/st=1000, rew=-20.38]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #298: test_reward: 39.285000 Â± 79.889698, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #299: 10001it [00:02, 4438.83it/s, bastaushy/loss=77.613, env_step=2990000, len=123, n/ep=10, n/st=1000, rew=20.40]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #299: test_reward: 47.445000 Â± 74.592137, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #300: 10001it [00:02, 4507.52it/s, bastaushy/loss=77.542, env_step=3000000, len=102, n/ep=5, n/st=1000, rew=-22.20]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #300: test_reward: 31.205000 Â± 82.120296, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #301: 10001it [00:02, 4466.25it/s, bastaushy/loss=77.613, env_step=3010000, len=121, n/ep=8, n/st=1000, rew=72.25]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #301: test_reward: 27.935000 Â± 83.801735, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #302: 10001it [00:02, 4402.84it/s, bastaushy/loss=78.148, env_step=3020000, len=108, n/ep=5, n/st=1000, rew=-94.60]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #302: test_reward: 30.890000 Â± 83.782026, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #303: 10001it [00:02, 4516.62it/s, bastaushy/loss=77.630, env_step=3030000, len=162, n/ep=5, n/st=1000, rew=-20.40]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #303: test_reward: 37.140000 Â± 80.381219, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #304: 10001it [00:02, 4585.49it/s, bastaushy/loss=77.557, env_step=3040000, len=124, n/ep=7, n/st=1000, rew=1.43]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #304: test_reward: 30.310000 Â± 83.349948, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #305: 10001it [00:02, 4499.52it/s, bastaushy/loss=76.988, env_step=3050000, len=115, n/ep=7, n/st=1000, rew=36.14]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #305: test_reward: 40.910000 Â± 80.499391, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #306: 10001it [00:02, 4544.03it/s, bastaushy/loss=77.644, env_step=3060000, len=126, n/ep=12, n/st=1000, rew=59.58]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #306: test_reward: 32.300000 Â± 83.267581, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #307: 10001it [00:02, 4560.33it/s, bastaushy/loss=78.790, env_step=3070000, len=95, n/ep=3, n/st=1000, rew=91.67]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #307: test_reward: 29.445000 Â± 81.902118, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #308: 10001it [00:02, 4555.37it/s, bastaushy/loss=77.306, env_step=3080000, len=140, n/ep=10, n/st=1000, rew=18.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #308: test_reward: 15.250000 Â± 87.370805, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #309: 10001it [00:02, 4604.31it/s, bastaushy/loss=76.582, env_step=3090000, len=125, n/ep=6, n/st=1000, rew=35.50]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #309: test_reward: 12.090000 Â± 88.142849, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #310: 10001it [00:02, 4520.21it/s, bastaushy/loss=76.041, env_step=3100000, len=127, n/ep=9, n/st=1000, rew=-35.33]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #310: test_reward: 27.885000 Â± 84.660981, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #311: 10001it [00:02, 4642.71it/s, bastaushy/loss=75.438, env_step=3110000, len=165, n/ep=7, n/st=1000, rew=-37.29]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #311: test_reward: 43.065000 Â± 77.536384, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #312: 10001it [00:02, 4617.87it/s, bastaushy/loss=75.733, env_step=3120000, len=129, n/ep=5, n/st=1000, rew=47.60]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #312: test_reward: 26.795000 Â± 82.539281, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #313: 10001it [00:02, 4645.15it/s, bastaushy/loss=75.407, env_step=3130000, len=152, n/ep=4, n/st=1000, rew=-46.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #313: test_reward: 15.975000 Â± 89.152983, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #314: 10001it [00:02, 4709.58it/s, bastaushy/loss=76.346, env_step=3140000, len=88, n/ep=10, n/st=1000, rew=19.60]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #314: test_reward: 20.165000 Â± 87.154046, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #315: 10001it [00:02, 4671.74it/s, bastaushy/loss=77.157, env_step=3150000, len=130, n/ep=7, n/st=1000, rew=61.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #315: test_reward: 32.760000 Â± 83.909430, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #316: 10001it [00:02, 4681.43it/s, bastaushy/loss=75.525, env_step=3160000, len=134, n/ep=10, n/st=1000, rew=-19.60]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #316: test_reward: 29.300000 Â± 84.334038, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #317: 10001it [00:02, 4710.14it/s, bastaushy/loss=75.971, env_step=3170000, len=122, n/ep=10, n/st=1000, rew=55.60]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #317: test_reward: -1.315000 Â± 89.066861, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #318: 10001it [00:02, 4643.43it/s, bastaushy/loss=77.125, env_step=3180000, len=123, n/ep=3, n/st=1000, rew=-34.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #318: test_reward: 21.205000 Â± 87.872652, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #319: 10001it [00:02, 4659.78it/s, bastaushy/loss=78.083, env_step=3190000, len=114, n/ep=9, n/st=1000, rew=30.89]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #319: test_reward: 22.350000 Â± 79.764638, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #320: 10001it [00:02, 4668.13it/s, bastaushy/loss=78.335, env_step=3200000, len=120, n/ep=8, n/st=1000, rew=-2.38]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #320: test_reward: 27.560000 Â± 83.384989, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #321: 10001it [00:02, 4774.43it/s, bastaushy/loss=79.045, env_step=3210000, len=133, n/ep=12, n/st=1000, rew=3.58]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #321: test_reward: 51.095000 Â± 74.136536, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #322: 10001it [00:02, 4634.56it/s, bastaushy/loss=77.496, env_step=3220000, len=115, n/ep=8, n/st=1000, rew=2.38]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #322: test_reward: 50.570000 Â± 75.276591, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #323: 10001it [00:02, 4704.00it/s, bastaushy/loss=77.527, env_step=3230000, len=126, n/ep=13, n/st=1000, rew=11.92]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #323: test_reward: 50.835000 Â± 71.983524, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #324: 10001it [00:02, 4703.87it/s, bastaushy/loss=77.391, env_step=3240000, len=128, n/ep=7, n/st=1000, rew=-39.14]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #324: test_reward: 37.640000 Â± 83.378777, best_reward: 55.940000 Â± 68.757737 in #258\n","output_type":"stream"},{"name":"stderr","text":"Epoch #325: 10001it [00:02, 4700.35it/s, bastaushy/loss=75.875, env_step=3250000, len=116, n/ep=5, n/st=1000, rew=19.40]                           \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 82, 'qostaushy': 18}\nEpoch #325: test_reward: 56.680000 Â± 70.902804, best_reward: 56.680000 Â± 70.902804 in #325\n","output_type":"stream"},{"name":"stderr","text":"Epoch #326: 10001it [00:02, 4622.56it/s, bastaushy/loss=77.111, env_step=3260000, len=95, n/ep=11, n/st=1000, rew=5.55]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #326: test_reward: 43.135000 Â± 78.587574, best_reward: 56.680000 Â± 70.902804 in #325\n","output_type":"stream"},{"name":"stderr","text":"Epoch #327: 10001it [00:02, 4629.79it/s, bastaushy/loss=75.954, env_step=3270000, len=125, n/ep=7, n/st=1000, rew=67.57]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #327: test_reward: 30.045000 Â± 80.643617, best_reward: 56.680000 Â± 70.902804 in #325\n","output_type":"stream"},{"name":"stderr","text":"Epoch #328: 10001it [00:02, 4679.98it/s, bastaushy/loss=76.198, env_step=3280000, len=118, n/ep=8, n/st=1000, rew=-24.12]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #328: test_reward: 44.565000 Â± 74.549821, best_reward: 56.680000 Â± 70.902804 in #325\n","output_type":"stream"},{"name":"stderr","text":"Epoch #329: 10001it [00:02, 4628.78it/s, bastaushy/loss=75.742, env_step=3290000, len=101, n/ep=4, n/st=1000, rew=-0.75]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #329: test_reward: 25.490000 Â± 84.263396, best_reward: 56.680000 Â± 70.902804 in #325\n","output_type":"stream"},{"name":"stderr","text":"Epoch #330: 10001it [00:02, 4654.03it/s, bastaushy/loss=75.117, env_step=3300000, len=157, n/ep=5, n/st=1000, rew=51.40]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #330: test_reward: 42.260000 Â± 79.315209, best_reward: 56.680000 Â± 70.902804 in #325\n","output_type":"stream"},{"name":"stderr","text":"Epoch #331: 10001it [00:02, 4695.13it/s, bastaushy/loss=73.820, env_step=3310000, len=125, n/ep=9, n/st=1000, rew=32.89]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #331: test_reward: 32.970000 Â± 82.780487, best_reward: 56.680000 Â± 70.902804 in #325\n","output_type":"stream"},{"name":"stderr","text":"Epoch #332: 10001it [00:02, 4737.44it/s, bastaushy/loss=75.116, env_step=3320000, len=107, n/ep=13, n/st=1000, rew=48.85]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #332: test_reward: 47.670000 Â± 79.032785, best_reward: 56.680000 Â± 70.902804 in #325\n","output_type":"stream"},{"name":"stderr","text":"Epoch #333: 10001it [00:02, 4679.48it/s, bastaushy/loss=75.749, env_step=3330000, len=150, n/ep=5, n/st=1000, rew=18.80]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #333: test_reward: 37.160000 Â± 82.223138, best_reward: 56.680000 Â± 70.902804 in #325\n","output_type":"stream"},{"name":"stderr","text":"Epoch #334: 10001it [00:02, 4585.95it/s, bastaushy/loss=75.287, env_step=3340000, len=101, n/ep=12, n/st=1000, rew=0.67]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #334: test_reward: 37.075000 Â± 80.688161, best_reward: 56.680000 Â± 70.902804 in #325\n","output_type":"stream"},{"name":"stderr","text":"Epoch #335: 10001it [00:02, 4674.78it/s, bastaushy/loss=74.893, env_step=3350000, len=103, n/ep=9, n/st=1000, rew=55.44]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #335: test_reward: 22.830000 Â± 87.939758, best_reward: 56.680000 Â± 70.902804 in #325\n","output_type":"stream"},{"name":"stderr","text":"Epoch #336: 10001it [00:02, 4659.76it/s, bastaushy/loss=75.283, env_step=3360000, len=116, n/ep=8, n/st=1000, rew=26.25]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #336: test_reward: 51.380000 Â± 74.774164, best_reward: 56.680000 Â± 70.902804 in #325\n","output_type":"stream"},{"name":"stderr","text":"Epoch #337: 10001it [00:02, 4684.01it/s, bastaushy/loss=74.383, env_step=3370000, len=147, n/ep=9, n/st=1000, rew=55.89]                           \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 75, 'qostaushy': 25}\nEpoch #337: test_reward: 58.520000 Â± 68.972818, best_reward: 58.520000 Â± 68.972818 in #337\n","output_type":"stream"},{"name":"stderr","text":"Epoch #338: 10001it [00:02, 4727.76it/s, bastaushy/loss=74.794, env_step=3380000, len=102, n/ep=11, n/st=1000, rew=60.91]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #338: test_reward: 32.255000 Â± 84.387143, best_reward: 58.520000 Â± 68.972818 in #337\n","output_type":"stream"},{"name":"stderr","text":"Epoch #339: 10001it [00:02, 4588.33it/s, bastaushy/loss=74.399, env_step=3390000, len=132, n/ep=7, n/st=1000, rew=41.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 87, 'qostaushy': 13}\nEpoch #339: test_reward: 61.105000 Â± 67.787786, best_reward: 61.105000 Â± 67.787786 in #339\n","output_type":"stream"},{"name":"stderr","text":"Epoch #340: 10001it [00:02, 4502.45it/s, bastaushy/loss=74.980, env_step=3400000, len=139, n/ep=10, n/st=1000, rew=-18.10]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #340: test_reward: 60.265000 Â± 70.083484, best_reward: 61.105000 Â± 67.787786 in #339\n","output_type":"stream"},{"name":"stderr","text":"Epoch #341: 10001it [00:02, 4518.29it/s, bastaushy/loss=76.765, env_step=3410000, len=122, n/ep=13, n/st=1000, rew=-18.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #341: test_reward: 57.655000 Â± 72.623040, best_reward: 61.105000 Â± 67.787786 in #339\n","output_type":"stream"},{"name":"stderr","text":"Epoch #342: 10001it [00:02, 4440.31it/s, bastaushy/loss=76.627, env_step=3420000, len=91, n/ep=3, n/st=1000, rew=94.00]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #342: test_reward: 36.810000 Â± 84.151969, best_reward: 61.105000 Â± 67.787786 in #339\n","output_type":"stream"},{"name":"stderr","text":"Epoch #343: 10001it [00:02, 4516.17it/s, bastaushy/loss=75.352, env_step=3430000, len=92, n/ep=7, n/st=1000, rew=16.43]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #343: test_reward: 52.645000 Â± 73.950855, best_reward: 61.105000 Â± 67.787786 in #339\n","output_type":"stream"},{"name":"stderr","text":"Epoch #344: 10001it [00:02, 4555.06it/s, bastaushy/loss=76.183, env_step=3440000, len=120, n/ep=9, n/st=1000, rew=11.89]                           \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 82, 'qostaushy': 18}\nEpoch #344: test_reward: 64.960000 Â± 59.417324, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #345: 10001it [00:02, 4537.78it/s, bastaushy/loss=76.992, env_step=3450000, len=137, n/ep=9, n/st=1000, rew=10.67]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #345: test_reward: 27.425000 Â± 82.402818, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #346: 10001it [00:02, 4413.38it/s, bastaushy/loss=75.480, env_step=3460000, len=123, n/ep=12, n/st=1000, rew=34.33]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #346: test_reward: 34.010000 Â± 81.554766, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #347: 10001it [00:02, 4594.68it/s, bastaushy/loss=77.141, env_step=3470000, len=110, n/ep=4, n/st=1000, rew=-4.50]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #347: test_reward: 57.070000 Â± 73.931963, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #348: 10001it [00:02, 4563.17it/s, bastaushy/loss=75.593, env_step=3480000, len=136, n/ep=5, n/st=1000, rew=-14.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #348: test_reward: 38.265000 Â± 81.373182, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #349: 10001it [00:02, 4402.12it/s, bastaushy/loss=75.335, env_step=3490000, len=139, n/ep=9, n/st=1000, rew=-10.11]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #349: test_reward: 40.645000 Â± 78.645527, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #350: 10001it [00:02, 4479.62it/s, bastaushy/loss=75.635, env_step=3500000, len=130, n/ep=8, n/st=1000, rew=1.00]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #350: test_reward: 45.665000 Â± 76.748634, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #351: 10001it [00:02, 4531.42it/s, bastaushy/loss=74.012, env_step=3510000, len=94, n/ep=10, n/st=1000, rew=-40.60]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #351: test_reward: 41.155000 Â± 79.018865, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #352: 10001it [00:02, 4451.06it/s, bastaushy/loss=73.670, env_step=3520000, len=125, n/ep=5, n/st=1000, rew=-29.20]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #352: test_reward: 29.640000 Â± 84.275384, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #353: 10001it [00:02, 4523.42it/s, bastaushy/loss=75.399, env_step=3530000, len=104, n/ep=8, n/st=1000, rew=2.50]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #353: test_reward: 33.670000 Â± 82.680476, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #354: 10001it [00:02, 4563.86it/s, bastaushy/loss=76.004, env_step=3540000, len=127, n/ep=14, n/st=1000, rew=26.93]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #354: test_reward: 26.595000 Â± 86.407181, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #355: 10001it [00:02, 4450.29it/s, bastaushy/loss=76.822, env_step=3550000, len=131, n/ep=10, n/st=1000, rew=39.20]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #355: test_reward: 57.670000 Â± 68.797900, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #356: 10001it [00:02, 4626.65it/s, bastaushy/loss=78.817, env_step=3560000, len=131, n/ep=10, n/st=1000, rew=-13.90]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #356: test_reward: 29.705000 Â± 82.262251, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #357: 10001it [00:02, 4587.88it/s, bastaushy/loss=76.756, env_step=3570000, len=107, n/ep=7, n/st=1000, rew=73.86]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #357: test_reward: 18.765000 Â± 86.867426, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #358: 10001it [00:02, 4424.70it/s, bastaushy/loss=78.182, env_step=3580000, len=107, n/ep=7, n/st=1000, rew=-9.29]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #358: test_reward: 38.760000 Â± 79.461578, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #359: 10001it [00:02, 4515.46it/s, bastaushy/loss=78.394, env_step=3590000, len=132, n/ep=10, n/st=1000, rew=24.60]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #359: test_reward: 27.985000 Â± 84.156014, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #360: 10001it [00:02, 4590.32it/s, bastaushy/loss=78.946, env_step=3600000, len=114, n/ep=11, n/st=1000, rew=77.27]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #360: test_reward: 51.465000 Â± 76.959787, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #361: 10001it [00:02, 4648.77it/s, bastaushy/loss=78.553, env_step=3610000, len=150, n/ep=5, n/st=1000, rew=16.40]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #361: test_reward: 34.700000 Â± 83.176980, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #362: 10001it [00:02, 4696.85it/s, bastaushy/loss=78.159, env_step=3620000, len=132, n/ep=7, n/st=1000, rew=68.86]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #362: test_reward: 44.955000 Â± 78.268340, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #363: 10001it [00:02, 4620.06it/s, bastaushy/loss=78.071, env_step=3630000, len=125, n/ep=7, n/st=1000, rew=15.43]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #363: test_reward: 22.080000 Â± 85.089915, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #364: 10001it [00:02, 4630.10it/s, bastaushy/loss=76.641, env_step=3640000, len=154, n/ep=6, n/st=1000, rew=-1.83]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #364: test_reward: 35.060000 Â± 78.691654, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #365: 10001it [00:02, 4619.26it/s, bastaushy/loss=77.678, env_step=3650000, len=121, n/ep=13, n/st=1000, rew=7.62]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #365: test_reward: 46.565000 Â± 75.878559, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #366: 10001it [00:02, 4667.17it/s, bastaushy/loss=77.084, env_step=3660000, len=117, n/ep=8, n/st=1000, rew=24.25]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #366: test_reward: 49.965000 Â± 73.113978, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #367: 10001it [00:02, 4610.01it/s, bastaushy/loss=77.831, env_step=3670000, len=117, n/ep=8, n/st=1000, rew=65.62]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #367: test_reward: 31.390000 Â± 82.966125, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #368: 10001it [00:02, 4675.83it/s, bastaushy/loss=74.994, env_step=3680000, len=116, n/ep=4, n/st=1000, rew=41.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #368: test_reward: 28.450000 Â± 80.697692, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #369: 10001it [00:02, 4637.49it/s, bastaushy/loss=75.819, env_step=3690000, len=117, n/ep=6, n/st=1000, rew=92.17]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #369: test_reward: 37.180000 Â± 80.170678, best_reward: 64.960000 Â± 59.417324 in #344\n","output_type":"stream"},{"name":"stderr","text":"Epoch #370: 10001it [00:02, 4561.87it/s, bastaushy/loss=74.731, env_step=3700000, len=146, n/ep=6, n/st=1000, rew=3.17]                            \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 82, 'qostaushy': 18}\nEpoch #370: test_reward: 69.335000 Â± 55.199663, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #371: 10001it [00:02, 4606.86it/s, bastaushy/loss=75.190, env_step=3710000, len=137, n/ep=9, n/st=1000, rew=-13.33]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #371: test_reward: 55.500000 Â± 70.675880, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #372: 10001it [00:02, 4653.33it/s, bastaushy/loss=75.557, env_step=3720000, len=128, n/ep=10, n/st=1000, rew=2.60]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #372: test_reward: 64.795000 Â± 58.877610, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #373: 10001it [00:02, 4638.11it/s, bastaushy/loss=75.019, env_step=3730000, len=142, n/ep=12, n/st=1000, rew=48.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #373: test_reward: 39.720000 Â± 77.533293, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #374: 10001it [00:02, 4540.88it/s, bastaushy/loss=75.740, env_step=3740000, len=98, n/ep=11, n/st=1000, rew=28.27]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #374: test_reward: 39.185000 Â± 75.628703, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #375: 10001it [00:02, 4642.18it/s, bastaushy/loss=74.107, env_step=3750000, len=114, n/ep=13, n/st=1000, rew=7.08]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #375: test_reward: 48.555000 Â± 74.756919, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #376: 10001it [00:02, 4551.19it/s, bastaushy/loss=74.271, env_step=3760000, len=139, n/ep=8, n/st=1000, rew=71.50]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #376: test_reward: 55.055000 Â± 71.148942, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #377: 10001it [00:02, 4664.46it/s, bastaushy/loss=74.891, env_step=3770000, len=108, n/ep=9, n/st=1000, rew=10.89]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #377: test_reward: 46.855000 Â± 77.253181, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #378: 10001it [00:02, 4616.85it/s, bastaushy/loss=76.028, env_step=3780000, len=142, n/ep=6, n/st=1000, rew=-28.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #378: test_reward: 51.425000 Â± 71.379299, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #379: 10001it [00:02, 4659.12it/s, bastaushy/loss=74.720, env_step=3790000, len=113, n/ep=5, n/st=1000, rew=19.80]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #379: test_reward: 43.190000 Â± 81.281018, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #380: 10001it [00:02, 4700.92it/s, bastaushy/loss=75.717, env_step=3800000, len=125, n/ep=9, n/st=1000, rew=9.33]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #380: test_reward: 52.760000 Â± 74.209719, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #381: 10001it [00:02, 4710.67it/s, bastaushy/loss=75.796, env_step=3810000, len=111, n/ep=7, n/st=1000, rew=65.29]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #381: test_reward: 42.925000 Â± 78.115807, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #382: 10001it [00:02, 4649.93it/s, bastaushy/loss=74.884, env_step=3820000, len=116, n/ep=9, n/st=1000, rew=33.67]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #382: test_reward: 61.700000 Â± 69.293867, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #383: 10001it [00:02, 4698.38it/s, bastaushy/loss=74.574, env_step=3830000, len=110, n/ep=7, n/st=1000, rew=-13.43]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #383: test_reward: 61.090000 Â± 69.492963, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #384: 10001it [00:02, 4714.62it/s, bastaushy/loss=73.555, env_step=3840000, len=143, n/ep=7, n/st=1000, rew=22.71]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #384: test_reward: 54.090000 Â± 70.298307, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #385: 10001it [00:02, 4745.37it/s, bastaushy/loss=74.118, env_step=3850000, len=135, n/ep=6, n/st=1000, rew=-0.50]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #385: test_reward: 40.555000 Â± 76.841440, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #386: 10001it [00:02, 4680.11it/s, bastaushy/loss=73.812, env_step=3860000, len=107, n/ep=11, n/st=1000, rew=11.18]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #386: test_reward: 66.335000 Â± 62.030096, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #387: 10001it [00:02, 4666.00it/s, bastaushy/loss=71.817, env_step=3870000, len=131, n/ep=12, n/st=1000, rew=-31.58]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #387: test_reward: 45.175000 Â± 76.884552, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #388: 10001it [00:02, 4683.59it/s, bastaushy/loss=71.941, env_step=3880000, len=133, n/ep=4, n/st=1000, rew=-45.25]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #388: test_reward: 41.175000 Â± 77.867544, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #389: 10001it [00:02, 4634.25it/s, bastaushy/loss=72.488, env_step=3890000, len=113, n/ep=13, n/st=1000, rew=-38.15]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #389: test_reward: 48.165000 Â± 77.153339, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #390: 10001it [00:02, 4648.33it/s, bastaushy/loss=71.230, env_step=3900000, len=119, n/ep=7, n/st=1000, rew=14.29]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #390: test_reward: 67.000000 Â± 61.745688, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #391: 10001it [00:02, 4692.12it/s, bastaushy/loss=70.665, env_step=3910000, len=100, n/ep=6, n/st=1000, rew=67.33]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #391: test_reward: 33.530000 Â± 83.189657, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #392: 10001it [00:02, 4520.44it/s, bastaushy/loss=71.653, env_step=3920000, len=103, n/ep=8, n/st=1000, rew=70.88]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #392: test_reward: 32.200000 Â± 82.309355, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #393: 10001it [00:02, 4641.35it/s, bastaushy/loss=72.157, env_step=3930000, len=93, n/ep=12, n/st=1000, rew=45.25]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #393: test_reward: 35.860000 Â± 81.485645, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #394: 10001it [00:02, 4737.36it/s, bastaushy/loss=72.355, env_step=3940000, len=99, n/ep=6, n/st=1000, rew=32.67]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #394: test_reward: 37.280000 Â± 78.921363, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #395: 10001it [00:02, 4601.32it/s, bastaushy/loss=71.184, env_step=3950000, len=94, n/ep=9, n/st=1000, rew=35.33]                              \n","output_type":"stream"},{"name":"stdout","text":"Epoch #395: test_reward: 50.225000 Â± 74.372336, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #396: 10001it [00:02, 4700.00it/s, bastaushy/loss=71.056, env_step=3960000, len=116, n/ep=8, n/st=1000, rew=-3.62]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #396: test_reward: 28.045000 Â± 84.092705, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #397: 10001it [00:02, 4649.46it/s, bastaushy/loss=72.904, env_step=3970000, len=121, n/ep=6, n/st=1000, rew=59.50]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #397: test_reward: 61.780000 Â± 65.096556, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #398: 10001it [00:02, 4518.49it/s, bastaushy/loss=72.987, env_step=3980000, len=139, n/ep=8, n/st=1000, rew=4.12]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #398: test_reward: 45.425000 Â± 77.730074, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #399: 10001it [00:02, 4470.12it/s, bastaushy/loss=72.941, env_step=3990000, len=124, n/ep=8, n/st=1000, rew=37.88]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #399: test_reward: 44.805000 Â± 75.640578, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #400: 10001it [00:02, 4646.76it/s, bastaushy/loss=74.107, env_step=4000000, len=99, n/ep=9, n/st=1000, rew=54.00]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #400: test_reward: 46.610000 Â± 74.747896, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #401: 10001it [00:02, 4625.01it/s, bastaushy/loss=76.576, env_step=4010000, len=131, n/ep=13, n/st=1000, rew=32.08]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #401: test_reward: 4.020000 Â± 90.203213, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #402: 10001it [00:02, 4658.75it/s, bastaushy/loss=76.009, env_step=4020000, len=114, n/ep=10, n/st=1000, rew=6.30]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #402: test_reward: 36.205000 Â± 78.607589, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #403: 10001it [00:02, 4661.88it/s, bastaushy/loss=76.065, env_step=4030000, len=128, n/ep=6, n/st=1000, rew=27.67]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #403: test_reward: 31.050000 Â± 82.348512, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #404: 10001it [00:02, 4538.58it/s, bastaushy/loss=76.324, env_step=4040000, len=108, n/ep=12, n/st=1000, rew=19.08]                            \n","output_type":"stream"},{"name":"stdout","text":"Epoch #404: test_reward: 49.005000 Â± 76.720955, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #405: 10001it [00:02, 4628.64it/s, bastaushy/loss=76.977, env_step=4050000, len=113, n/ep=11, n/st=1000, rew=58.73]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #405: test_reward: 28.710000 Â± 82.329921, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #406: 10001it [00:02, 4627.17it/s, bastaushy/loss=76.526, env_step=4060000, len=95, n/ep=12, n/st=1000, rew=60.83]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #406: test_reward: 56.225000 Â± 70.809282, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #407: 10001it [00:02, 4370.59it/s, bastaushy/loss=75.848, env_step=4070000, len=137, n/ep=8, n/st=1000, rew=24.12]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #407: test_reward: 41.025000 Â± 78.563760, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #408: 10001it [00:02, 4447.74it/s, bastaushy/loss=76.100, env_step=4080000, len=145, n/ep=10, n/st=1000, rew=19.90]                           \n","output_type":"stream"},{"name":"stdout","text":"Epoch #408: test_reward: 42.015000 Â± 77.952260, best_reward: 69.335000 Â± 55.199663 in #370\n","output_type":"stream"},{"name":"stderr","text":"Epoch #409: 10001it [00:02, 4569.05it/s, bastaushy/loss=75.438, env_step=4090000, len=118, n/ep=6, n/st=1000, rew=-28.00]                           \n","output_type":"stream"},{"name":"stdout","text":"Agent bastaushy vs random {'bastaushy': 91, 'qostaushy': 9}\nEpoch #409: test_reward: 73.750000 Â± 53.761208, best_reward: 73.750000 Â± 53.761208 in #409\n","output_type":"stream"},{"name":"stderr","text":"Epoch #410: 10001it [00:02, 4566.70it/s, bastaushy/loss=74.171, env_step=4100000, len=124, n/ep=8, n/st=1000, rew=3.00]                             \n","output_type":"stream"},{"name":"stdout","text":"Epoch #410: test_reward: 42.460000 Â± 75.035448, best_reward: 73.750000 Â± 53.761208 in #409\n","output_type":"stream"},{"name":"stderr","text":"Epoch #411: 10001it [00:02, 4603.45it/s, bastaushy/loss=71.296, env_step=4110000, len=98, n/ep=8, n/st=1000, rew=46.12]                              \n","output_type":"stream"},{"name":"stdout","text":"Epoch #411: test_reward: 41.440000 Â± 77.789179, best_reward: 73.750000 Â± 53.761208 in #409\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}